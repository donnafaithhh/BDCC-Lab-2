{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b1154d9-f090-4b0c-9709-0bcb8f0423a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T13:20:22.994663Z",
     "iopub.status.busy": "2025-11-24T13:20:22.994465Z",
     "iopub.status.idle": "2025-11-24T13:20:23.003678Z",
     "shell.execute_reply": "2025-11-24T13:20:23.002845Z",
     "shell.execute_reply.started": "2025-11-24T13:20:22.994642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script src=\"require.js\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<script src=\"require.js\"></script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166f8f17-6c4f-4e3d-b006-f6c97d9bb74a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T13:20:23.004506Z",
     "iopub.status.busy": "2025-11-24T13:20:23.004270Z",
     "iopub.status.idle": "2025-11-24T13:20:23.010207Z",
     "shell.execute_reply": "2025-11-24T13:20:23.009336Z",
     "shell.execute_reply.started": "2025-11-24T13:20:23.004478Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js \"></script><script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       "if (code_show){\n",
       "$('div.jp-CodeCell > div.jp-Cell-inputWrapper').hide();\n",
       "} else {\n",
       "$('div.jp-CodeCell > div.jp-Cell-inputWrapper').show();\n",
       "}\n",
       "code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);</script><form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js \"></script><script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    "if (code_show){\n",
    "$('div.jp-CodeCell > div.jp-Cell-inputWrapper').hide();\n",
    "} else {\n",
    "$('div.jp-CodeCell > div.jp-Cell-inputWrapper').show();\n",
    "}\n",
    "code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);</script><form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e9b536-8ccd-4527-95c7-c8c359fe5ac2",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"Figures/Title.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d7c269-e0b2-4661-8649-fda38188f9e1",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #270f47; color: #eed47c; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "# I. Abstract\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6904207-bbbc-452b-a247-bcc738367c62",
   "metadata": {},
   "source": [
    "Cryptocurrency trading has grown in popularity recently, yet it remains challenging for first-time investors to learn due to the large number of assets and quote currencies available on platforms like Binance. \n",
    "This study investigates how volatility, price stability, and trading activity patterns differ across base cryptocurrencies and their quote currencies to provide data-driven guidance for beginners. \n",
    "Using historical Binance data from 2017 to 2022, we created a Spark DataFrame to handle over 30 Parquet files totaling 33 GB. \n",
    "The dataset included trading information such as prices, volumes, and number of trades. \n",
    "Exploratory data analysis focused on base currencies with at least eight quote currencies to enable meaningful comparisons. \n",
    "Correlation analyses examined how returns of base currencies relate to different quote currencies and to each other. \n",
    "Annual volatility was computed from daily log returns to identify periods of high and low price fluctuations, while trading volume patterns were analyzed to assess market activity. \n",
    "Results indicate that major cryptocurrencies like BTC and ETH exhibit high return correlations across different quote currencies, suggesting their performance is largely independent of the quote currency and generally stable. \n",
    "Less established coins like ADA show lower correlations and higher sensitivity to macroeconomic conditions, indicating greater risk for beginners. \n",
    "Volatility tends to spike following the introduction of new quote currencies, while trading volume does not consistently predict returns, reflecting unique market behaviors. \n",
    "For first-time traders, the study recommends prioritizing high-liquidity, high-stability pairs such as BTC-USDT or ETH-USDT, monitoring volatility to time trades, and using smaller positions for more volatile or less established coins.\n",
    "However, it must be noted that when replicating this study, a more recent dataset should be used since we only used data from 2017 until 2022.\n",
    "For more accurate results, future work should incorporate data from at least a year from present onwards. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a341bdc-50d2-4fe5-80c1-a5aa1d111e3e",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #270f47; color: #eed47c; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "# II. Introduction\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de9aa4e-db3d-452d-942c-56147534eb52",
   "metadata": {},
   "source": [
    "**Understanding Cryptocurrency**\n",
    "\n",
    "In recent years, trading in cryptocurrency has started to gain traction among many traders. \n",
    "However, the field, in itself, could be obscure especially for new traders trying to learn more about it and trying to penetrate the trading market. \n",
    "Before we discuss more about trading in cryptocurrency, let us discuss first what cryptocurrency is. \n",
    "There are a lot of things that we can say about cryptocurrency, but we will only be talking about the basic things that beginner traders need to know. \n",
    "\n",
    "Cryptocurrency is a type of digital money that is not issued or governed by any central authority like a government or bank. \n",
    "Usually, they are considered an alternative asset and investment where many people buy them to hold in hopes of the value appreciating over time (CryptoCrafted, 2025).\n",
    "When trading, everyone has to deal with a trading pair which consists of two currencies: base currency and quote currency. \n",
    "The base currency represents the asset  being bought or sold.\n",
    "The quote currency is used to express the value or price of one unit of the base currency.\n",
    "For example, in a BTC-USDT pair, Bitcoin (BTC) is the base currency and Tether (USDT) is the quote currency, meaning the price shows how many USDT are needed to buy one BTC. \n",
    "Understanding which currency is the base and which is the quote is essential for traders to accurately interpret prices, calculate profits and losses, and manage risk (Bitcoin.com, 2025, MK Manoylov, 2024). \n",
    "\n",
    "To further expound, quote currencies are classified into three main categories: fiat-backed stablecoins, crypto-collaterized stablecoins, and non-stable quote currencies (Kraken Learn team, 2024). \n",
    "Fiat-backed stablecoins are pegged to traditional government-issued currencies like the US dollar or the Euro. \n",
    "This is so maintain price stability. \n",
    "Crypto-collateralized stablecoins are backed by other cryptocurrencies held in reserve to provide security and liquidity. \n",
    "Non-stable quote currencies are the ones with the most volatile price behavior. \n",
    "Good traders know which ones to choose to match their risk appetite, stability needs, and trading strategies within the crypto market. \n",
    "\n",
    "**Understanding Binance**\n",
    "\n",
    "For traders to participate in trading cryptocurrency, usually they have to go through a platform in order to buy, sell, and trade Bitcoin, Ethereum, and other altcoins. \n",
    "One of the known and popular platforms is Binance. \n",
    "According to BSO Editorial (2023), Binance is one of the largest cryptocurrency exchanges in the world.\n",
    "They offer the trading services for a wide range of digital assets and 530 crypto-to-crypto trading pairs alongside futures contracts for various cryptocurrencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23f32a1-8007-44ce-8dd0-afb81513f191",
   "metadata": {},
   "source": [
    "<div style=\"color: #270f47; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8908625f-f167-4389-920b-f8406d7bf60c",
   "metadata": {},
   "source": [
    "For first time users, it is hard to trading in cryptocurrency could be challenging.\n",
    "There are a lot of options to choose from, and a lot of quote currencies that could potentially change the value of your currencies. \n",
    "In this report, we want to answer the question: **For a first-time investor, how do the volatility, price stability, and trading activity patterns differ among the available different cryptocurrencies and their quote currencies?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f780b18a-bf5a-4c0e-804f-d8d76eda1351",
   "metadata": {},
   "source": [
    "<div style=\"color: #270f47; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "## Motivation\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9f5cbc-8652-4d1b-982d-eef734dd3b59",
   "metadata": {},
   "source": [
    "We do not have prior knowledge about cryptocurrency and Binance. \n",
    "Despite this, we wanted to do this study because we want to give data-driven guidance for beginner traders like us. \n",
    "As mentioned earlier, the Binance platform offers a vast array of options, making it difficult for beginners to understand which assets are stable, which are volatile, and when the best times to trade are. \n",
    "By analyzing historical data, we seek to uncover patterns that can inform smarter, less risky trading decisions. \n",
    "Ultimately, we want to transform complex market data into actionable insights that can help first-time users build confidence and develop effective trading strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab387656-4acc-494c-8bbc-82a3e008dda0",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #270f47; color: #eed47c; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "# III. Methodology Overview\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9ca1c2-90bf-4f9c-b61d-5d2fcb45fe6d",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"Figures/Methodology Overview.png\" />\n",
    "</div>\n",
    "\n",
    "**Figure 1.** Methodology Overview\n",
    "\n",
    "Figure 1 shows the methodology overview of this study.\n",
    "Our methodology consists of a four step process starting with the collection of historical Binance data, followed by exploratory data analysis, data processing, and the results and discussion. \n",
    "Below would be a short summary of each of the different steps:\n",
    "1. **Data Collection**: Here, we collect publicly available historical Binance data focusing on the closing price. Since the dataset is very big, we stored it in a Spark DataFrame.\n",
    "2. **Exploratory Data Analysis**: Here, we prepared and cleaned the dataset to ensure that it is suitable for further analysis. EDA is used to understand the behavior of the closing price for different classifications: base currencies, quote currencies, and even their classifications. We filtered out base currencies with fewer than eight quote currencies to ensure meaningful comparisons. Correlation analyses were conducted to examine relationships between base currency returns across different quote currencies and among base currencies within the same quote currency. \n",
    "3. **Data Processing**: In this step, we want to get answers for our research problem which is to find out the volatility, price stability, and trading activity patterns among the three classifications: cryptocurrency, fiat-based tokens, and stablecoin. Annual volatility was computed using the standard deviation of daily log returns, scaled by the square root of 365, to identify fluctuations and trends. We also explored the relationship between trading volume and returns to detect patterns in market participation and trading behavior for different base currencies.\n",
    "4. **Results and Discussion**: Based on what we find, we want to discuss what this could mean for investors, mention our perceived benefits and disadvantages, and recommend further steps. Afterwards, we will summarize findings in the recommendations and conclusion section.\n",
    "\n",
    "A more specific and detailed description of the different steps and diagrams would be provided in their respective sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8785c701-4134-489a-9484-ce034836a094",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #270f47; color: #eed47c; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "# IV. Data Collection\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6abbe7-53dc-409e-a9df-fbc3212d4835",
   "metadata": {},
   "source": [
    "<div style=\"color: #270f47; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "## Data Source\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eec5a0a-ee6e-4ab2-923c-5a53a6f70173",
   "metadata": {},
   "source": [
    "We gathered data from the Binance Full History dataset available on the Jojie-collected public datasets of the Asian Institute of Management. \n",
    "The directory is as follows: `/mnt/data/public/binance-full-history`.\n",
    "This dataset consists of more than 30 Parquet files that correspond to the information per base currency in its quote currency.\n",
    "The dataset, as a whole, takes up 33 GB of data, so it would not be feasible to use the typical Python operations to handle all of it. \n",
    "Instead, we used Apache Spark, and created a Spark DataFrame just to contain all the information we need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04a6fd5-292e-44bb-98b0-cb9ad04aeb4b",
   "metadata": {},
   "source": [
    "<div style=\"color: #270f47; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "## Data Description\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d410b4f-5ed0-4f96-8b91-3d572d38e4d7",
   "metadata": {},
   "source": [
    "The following features are consistent within all Parquet files in the Binance Full History dataset:\n",
    "\n",
    "| Feature Name | Data Description | Data Type |\n",
    "|-------------|-----------------|-----------|\n",
    "| open | Opening price of the trading period | float |\n",
    "| high | Highest price during the trading period | float |\n",
    "| low | Lowest price during the trading period | float |\n",
    "| close | Closing price of the trading period | float |\n",
    "| volume | Total volume of base asset traded | float |\n",
    "| quote_asset_volume | Total volume of quote asset traded | float |\n",
    "| number_of_trades | Total number of trades executed | integer |\n",
    "| taker_buy_base_asset_volume | Volume of base asset bought by takers | float |\n",
    "| taker_buy_quote_asset_volume | Volume of quote asset bought by takers | float |\n",
    "| open_time | Timestamp when the trading period started | timestamp_ntz |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1ab3dc-3ac2-4a5d-a76b-ed6d72786398",
   "metadata": {},
   "source": [
    "<div style=\"color: #270f47; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "## Data Collection and DataFrame Creation\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1376c807-2dae-4b52-97f7-d63051bafc21",
   "metadata": {},
   "source": [
    "Since there are a lot of files, and the entire dataset sums to a total of 33 GB, we had to use Apache Spark to handle the data. \n",
    "To summarize the code below, we created a Spark DataFrame from all the information available.\n",
    "Here, we created new features: `base_currency`, `quote_currency`, and `classification`. \n",
    "These three are not anywhere in the previously shown data dictionary because they are information you can only get from the file names of the Parquet files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bad2016e-d536-4026-8eaf-eee1b3573808",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T14:13:15.102579Z",
     "iopub.status.busy": "2025-11-24T14:13:15.100924Z",
     "iopub.status.idle": "2025-11-24T14:13:15.113746Z",
     "shell.execute_reply": "2025-11-24T14:13:15.112524Z",
     "shell.execute_reply.started": "2025-11-24T14:13:15.102513Z"
    }
   },
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import math\n",
    "\n",
    "# spark imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, split, when, lit,  to_date, row_number\n",
    "from pyspark.sql.functions import regexp_extract, input_file_name\n",
    "from pyspark.sql.functions import year, month, dayofmonth, to_date\n",
    "from pyspark.sql.functions import sum as spark_sum\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# scipy imports\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7cf81bd-f344-4778-b6e8-70991b25a73e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T13:20:24.782058Z",
     "iopub.status.busy": "2025-11-24T13:20:24.781747Z",
     "iopub.status.idle": "2025-11-24T13:20:25.212442Z",
     "shell.execute_reply": "2025-11-24T13:20:25.211716Z",
     "shell.execute_reply.started": "2025-11-24T13:20:24.782038Z"
    }
   },
   "outputs": [],
   "source": [
    "# Directory containing the parquet files\n",
    "directory = '/mnt/data/public/binance-full-history'\n",
    "files = [f for f in os.listdir(directory) if f.endswith('.parquet')]\n",
    "\n",
    "base_quote_counts = {}\n",
    "\n",
    "for file in files:\n",
    "    base_currency = file.split('-')[0]\n",
    "    quote_currency = file.split('-')[1].replace('.parquet', '')\n",
    "\n",
    "    if base_currency not in base_quote_counts:\n",
    "        base_quote_counts[base_currency] = set()\n",
    "\n",
    "    base_quote_counts[base_currency].add(quote_currency)\n",
    "\n",
    "base_counts = {base: len(quotes) for base, quotes in base_quote_counts.items()}\n",
    "\n",
    "counts_df = pd.DataFrame({\n",
    "    'base_currency': list(base_counts.keys()),\n",
    "    'quote_count': list(base_counts.values())\n",
    "})\n",
    "\n",
    "quote_count_distribution = counts_df['quote_count'].value_counts().sort_index()\n",
    "\n",
    "# plotting\n",
    "plt.figure(figsize=(15, 8))\n",
    "bars = plt.bar(quote_count_distribution.index, quote_count_distribution.values)\n",
    "\n",
    "for bar in bars:\n",
    "    bar.set_color('#bba9de')\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2., height + 0.1,\n",
    "        f'{int(height)}', ha='center', va='bottom'\n",
    "    )\n",
    "\n",
    "plt.xlabel('Number of Quote Currencies')\n",
    "plt.ylabel('Number of Base Currencies')\n",
    "plt.title('Distribution of Base Currencies by Number of Quote Currencies')\n",
    "plt.grid(axis='x', alpha=0)\n",
    "plt.xticks(quote_count_distribution.index)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Figures/Distribution_of_base_quote.png')\n",
    "plt.close()\n",
    "\n",
    "top_bases = counts_df.nlargest(10, 'quote_count')\n",
    "common_quotes = set.intersection(\n",
    "    *(base_quote_counts[base] for base in top_bases['base_currency'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cff0d6-f690-4cc9-82df-085b4c82a537",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"Figures/Distribution_of_base_quote.png\"/>\n",
    "</div>\n",
    "\n",
    "**Figure 2.** Distribution of the number of base currencies per number of quote currency.\n",
    "\n",
    "To put in other words, Figure 2 shows the number of base currencies that have $n$ amount of quote currencies.\n",
    "As seen here, there are a lot of base currencies that can only be traded with one quote currency.\n",
    "Since we want to do a comparative analysis on the different quote currencies and their relationship to the base currency, we will only look at the base currencies with at least 8 quote currencies.\n",
    "This is to ensure that they have some quote currencies in common which can help us understand the relationship between both factors more. \n",
    "This cuts down on a lot of irrelevant data that are not important to our analysis and makes this more computationally efficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9427eb2-7db9-4b4f-9878-df592dfcf376",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T13:20:25.213331Z",
     "iopub.status.busy": "2025-11-24T13:20:25.213108Z",
     "iopub.status.idle": "2025-11-24T13:20:41.402663Z",
     "shell.execute_reply": "2025-11-24T13:20:41.401162Z",
     "shell.execute_reply.started": "2025-11-24T13:20:25.213303Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"TopBasesAnalysis\").getOrCreate()\n",
    "\n",
    "# Getting only target files\n",
    "file_data = []\n",
    "for base in top_bases['base_currency']:\n",
    "    for quote in common_quotes:\n",
    "        file_name = f\"{base}-{quote}.parquet\"\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        if os.path.exists(file_path):\n",
    "            file_data.append((file_path, base, quote))\n",
    "\n",
    "# Define classification mapping\n",
    "classification_map = {\n",
    "    'stablecoin': ['BUSD', 'USDT'],\n",
    "    'fiat': ['EUR']\n",
    "}\n",
    "\n",
    "# Create DataFrames for each file and add columns\n",
    "dfs = []\n",
    "for file_path, base, quote in file_data:\n",
    "    df = spark.read.parquet(file_path)\n",
    "    df = (\n",
    "        df.withColumn(\"base_currency\", lit(base))\n",
    "        .withColumn(\"quote_currency\", lit(quote))\n",
    "        .withColumn(\n",
    "            \"classification\",\n",
    "            when(lit(quote).isin(classification_map['stablecoin']), lit('stablecoin'))\n",
    "            .when(lit(quote).isin(classification_map['fiat']), lit('fiat'))\n",
    "            .otherwise(lit('cryptocurrency'))\n",
    "        )\n",
    "    )\n",
    "    dfs.append(df)\n",
    "\n",
    "# Union all DataFrames\n",
    "spark_df = reduce(lambda df1, df2: df1.union(df2), dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ec9e34-a90e-476e-af69-a98d00b52ac4",
   "metadata": {},
   "source": [
    "The schema, also features, of the new Spark DataFrame is as follows:\n",
    "\n",
    "| Feature | Description | Data Type |\n",
    "|---------|-------------|-----------|\n",
    "| open | Opening price of the trading period | float |\n",
    "| high | Highest price during the trading period | float |\n",
    "| low | Lowest price during the trading period | float |\n",
    "| close | Closing price of the trading period | float |\n",
    "| volume | Total trading volume in base currency | float |\n",
    "| quote_asset_volume | Total trading volume in quote currency | float |\n",
    "| number_of_trades | Total number of trades executed during the period | integer |\n",
    "| taker_buy_base_asset_volume | Volume of base asset bought by takers (market orders) | float |\n",
    "| taker_buy_quote_asset_volume | Volume of quote asset bought by takers (market orders) | float |\n",
    "| open_time | Timestamp indicating the start of the trading period | timestamp_ntz |\n",
    "| base_currency | The base currency in the trading pair (e.g., BTC, ETH) | string |\n",
    "| quote_currency | The quote currency in the trading pair (e.g., USDT, BUSD) | string |\n",
    "| classification | Classification of the quote currency (stablecoin/fiat/cryptocurrency) | string |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01287a08-ddbb-4eb2-aee9-b73ffc9761c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T13:20:41.404309Z",
     "iopub.status.busy": "2025-11-24T13:20:41.403976Z",
     "iopub.status.idle": "2025-11-24T13:20:54.621227Z",
     "shell.execute_reply": "2025-11-24T13:20:54.620083Z",
     "shell.execute_reply.started": "2025-11-24T13:20:41.404276Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number of null entries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>open</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>close</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volume</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_asset_volume</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_trades</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taker_buy_base_asset_volume</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taker_buy_quote_asset_volume</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_time</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_currency</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_currency</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classification</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              number of null entries\n",
       "open                                               0\n",
       "high                                               0\n",
       "low                                                0\n",
       "close                                              0\n",
       "volume                                             0\n",
       "quote_asset_volume                                 0\n",
       "number_of_trades                                   0\n",
       "taker_buy_base_asset_volume                        0\n",
       "taker_buy_quote_asset_volume                       0\n",
       "open_time                                          0\n",
       "base_currency                                      0\n",
       "quote_currency                                     0\n",
       "classification                                     0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the number of null values\n",
    "null_counts_pd = spark_df.select([\n",
    "    spark_sum(col(c).isNull().cast(\"int\")).alias(c)\n",
    "    for c in spark_df.columns\n",
    "]).toPandas().T\n",
    "\n",
    "null_counts_pd.columns = [\"number of null entries\"]\n",
    "null_counts_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3dfcc8-a4c6-4b25-8e4d-56379b056b7b",
   "metadata": {},
   "source": [
    "Based on the results above, there seems to be no null values, so we do not have to handle any null values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d0e7d0-206c-4e83-bfc7-8e09520c386d",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #270f47; color: #eed47c; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "# V. Exploratory Data Analysis\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f712cbd-35be-466d-b2d1-22d4d6c4ef1f",
   "metadata": {},
   "source": [
    "<div style=\"color: #270f47; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "## Base Currencies per Quote Currency by Year\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "891f3420-564d-44f5-a6b8-fe190aa9938d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T13:20:54.622701Z",
     "iopub.status.busy": "2025-11-24T13:20:54.622426Z",
     "iopub.status.idle": "2025-11-24T13:21:09.668164Z",
     "shell.execute_reply": "2025-11-24T13:21:09.667270Z",
     "shell.execute_reply.started": "2025-11-24T13:20:54.622676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: Figures/Base Currencies per Quote Currency (Line Chart).png\n"
     ]
    }
   ],
   "source": [
    "# Work with Spark DataFrame\n",
    "df = spark_df\n",
    "\n",
    "# Add a column for the year extracted from open_time\n",
    "df_with_year = df.withColumn(\"year\", F.year(\"open_time\"))\n",
    "\n",
    "# Count distinct base currencies per quote currency per year\n",
    "quote_base_counts = (\n",
    "    df_with_year\n",
    "    .groupBy(\"year\", \"quote_currency\")\n",
    "    .agg(F.countDistinct(\"base_currency\").alias(\"n_base_currencies\"))\n",
    ")\n",
    "\n",
    "# Filter for target quote currencies\n",
    "target_quotes = [\"USDT\", \"BUSD\", \"EUR\"]\n",
    "quote_filtered = quote_base_counts.filter(F.col(\"quote_currency\").isin(target_quotes))\n",
    "\n",
    "# Convert to Pandas DataFrame for plotting and sort by year\n",
    "plot_df = quote_filtered.toPandas().sort_values(\"year\")\n",
    "\n",
    "# Set Seaborn style and create the figure\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot line chart of number of base currencies over time per quote currency\n",
    "sns.lineplot(\n",
    "    data=plot_df,\n",
    "    x=\"year\",\n",
    "    y=\"n_base_currencies\",\n",
    "    hue=\"quote_currency\",\n",
    "    marker=\"o\"\n",
    ")\n",
    "\n",
    "# Customize plot\n",
    "plt.title(\"Number of Base Currencies per Quote Currency Over Time\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Base Currencies\")\n",
    "plt.ylim(0, 10.5)\n",
    "plt.xticks(sorted(plot_df[\"year\"].unique()))\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Save figure\n",
    "save_path = \"Figures/Base Currencies per Quote Currency (Line Chart).png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved to:\", save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1fe656-f1b2-42f2-b412-24e28c69d3e5",
   "metadata": {},
   "source": [
    "The code above was generated using ChatGPT. It took around 16 seconds to load.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"Figures/Base Currencies per Quote Currency (Line Chart).png\" />\n",
    "</div>\n",
    "\n",
    "**Figure 3.** The number of base currencies per quote currencies over time.\n",
    "\n",
    "Figure 3 shows how many distinct base currencies exist within each quote currency (USDT, EUR, and BUSD) across all years of the given data. Initially, it could be observed that USDT is the only quote currency that exists in the years 2017 and 2018. Beyond that, more quote currencies are considered in with BUSD emerging in 2019 and EUR coming in 2020. \n",
    "An article by Binance mentions that on February 3, 2019, the company announced a Launchpad project for the first time, and this event started the \"*IEO (Initial Exchange Offering) wave*\" that brought a rise in the number of assets being listed on the website (Binance, 2024). \n",
    "Furthermore, as the timeline leads into 2022, the market structure matures as the number of base currencies under BUSD and EUR increases.\n",
    "By the conclusion of the timeline, all quote currencies have 10 base currencies under their title."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e71967-f35b-4352-a8c3-65d67d9aa720",
   "metadata": {},
   "source": [
    "<div style=\"color: #270f47; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "## Correlation of Base Currency Returns Across Target Quote Pairs \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff0fbd82-525f-4b61-8088-e1989d50ac96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T13:53:28.475069Z",
     "iopub.status.busy": "2025-11-24T13:53:28.474364Z",
     "iopub.status.idle": "2025-11-24T13:54:36.902523Z",
     "shell.execute_reply": "2025-11-24T13:54:36.901535Z",
     "shell.execute_reply.started": "2025-11-24T13:53:28.475011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: Figures/Correlation of Returns Across Three Random Base Currencies Across Target Quote Pairs.png\n"
     ]
    }
   ],
   "source": [
    "# Compute returns with lag over each base-quote pair\n",
    "w = Window.partitionBy(\"base_currency\", \"quote_currency\").orderBy(\"open_time\")\n",
    "\n",
    "df_returns = (\n",
    "    spark_df\n",
    "    .withColumn(\"year\", F.year(\"open_time\"))\n",
    "    .withColumn(\"prev_close\", F.lag(\"close\").over(w))\n",
    "    .withColumn(\n",
    "        \"return\",\n",
    "        (F.col(\"close\") - F.col(\"prev_close\")) / F.col(\"prev_close\")\n",
    "    )\n",
    "    .filter(F.col(\"prev_close\").isNotNull())\n",
    ")\n",
    "\n",
    "# Use this order so A,B,C = BUSD, EUR, USDT\n",
    "target_quotes = [\"BUSD\", \"EUR\", \"USDT\"]\n",
    "\n",
    "# Collect sets of quotes each base trades against\n",
    "bases_with_quotes = (\n",
    "    df_returns\n",
    "    .filter(F.col(\"quote_currency\").isin(target_quotes))\n",
    "    .groupBy(\"base_currency\")\n",
    "    .agg(F.collect_set(\"quote_currency\").alias(\"quotes\"))\n",
    ")\n",
    "\n",
    "# Keep only bases that have all 3 quotes\n",
    "bases_complete = (\n",
    "    bases_with_quotes\n",
    "    .filter(F.size(\"quotes\") == len(target_quotes))\n",
    "    .select(\"base_currency\")\n",
    "    .toPandas()[\"base_currency\"]\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "if len(bases_complete) < 3:\n",
    "    raise ValueError(\n",
    "        f\"Not enough bases with all {target_quotes}. \\\n",
    "        Found only: {bases_complete}\"\n",
    "    )\n",
    "\n",
    "# Select specific bases if valid\n",
    "desired_bases = [\"ADA\", \"ETH\", \"BTC\"]\n",
    "base_by_row = [b for b in desired_bases if b in bases_complete]\n",
    "\n",
    "if len(base_by_row) < 3:\n",
    "    raise ValueError(\n",
    "        f\"One or more of {desired_bases} do not have all {target_quotes} pairs. \"\n",
    "        f\"Valid bases with all quotes are: {bases_complete}\"\n",
    "    )\n",
    "\n",
    "# Labels for plotting rows\n",
    "row_labels = [\n",
    "    f\"Base 1: {base_by_row[0]}\",\n",
    "    f\"Base 2: {base_by_row[1]}\",\n",
    "    f\"Base 3: {base_by_row[2]}\",\n",
    "]\n",
    "\n",
    "# Filter for selected bases and target quotes\n",
    "df_sel = (\n",
    "    df_returns\n",
    "    .filter(F.col(\"base_currency\").isin(base_by_row))\n",
    "    .filter(F.col(\"quote_currency\").isin(target_quotes))\n",
    ")\n",
    "\n",
    "df_small = df_sel.filter(F.minute(\"open_time\") == 0)\n",
    "\n",
    "# Convert to pandas and sort\n",
    "pdf = (\n",
    "    df_small\n",
    "    .select(\"open_time\", \"year\", \"quote_currency\", \"base_currency\", \"return\")\n",
    "    .toPandas()\n",
    ")\n",
    "pdf = pdf.sort_values([\"year\", \"quote_currency\", \"open_time\"])\n",
    "\n",
    "years = list(range(2017, 2023))\n",
    "\n",
    "# Create subplots\n",
    "n_rows, n_cols = 3, len(years)\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=n_rows,\n",
    "    ncols=n_cols,\n",
    "    figsize=(4 * n_cols, 4 * n_rows),\n",
    "    squeeze=False,\n",
    "    sharex=True,\n",
    "    sharey=True\n",
    ")\n",
    "\n",
    "# Loop over bases and years to plot correlation heatmaps\n",
    "for i, base in enumerate(base_by_row):\n",
    "    for j, year in enumerate(years):\n",
    "        ax = axes[i, j]\n",
    "\n",
    "        sub = pdf[\n",
    "            (pdf[\"base_currency\"] == base) &\n",
    "            (pdf[\"year\"] == year) &\n",
    "            (pdf[\"quote_currency\"].isin(target_quotes))\n",
    "        ]\n",
    "\n",
    "        # If no data, create blank grid\n",
    "        if sub.empty:\n",
    "            ax.set_xticks(range(len(target_quotes)))\n",
    "            ax.set_yticks(range(len(target_quotes)))\n",
    "            ax.set_xticklabels(target_quotes, fontsize=10)\n",
    "            ax.set_yticklabels(target_quotes, fontsize=10)\n",
    "            ax.tick_params(axis=\"x\", labelrotation=0)\n",
    "\n",
    "            for pos in range(len(target_quotes)+1):\n",
    "                ax.axhline(pos - 0.5, color=\"white\", linewidth=0.5)\n",
    "                ax.axvline(pos - 0.5, color=\"white\", linewidth=0.5)\n",
    "\n",
    "            ax.set_xlim(-0.5, len(target_quotes)-0.5)\n",
    "            ax.set_ylim(len(target_quotes)-0.5, -0.5)\n",
    "\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_visible(False)\n",
    "\n",
    "            continue\n",
    "\n",
    "        # Pivot data for correlation calculation\n",
    "        wide = sub.pivot_table(\n",
    "            index=\"open_time\",\n",
    "            columns=\"quote_currency\",\n",
    "            values=\"return\"\n",
    "        ).reindex(columns=target_quotes)\n",
    "\n",
    "        corr = wide.corr()\n",
    "\n",
    "        # If correlation is all NaN, draw empty grid\n",
    "        if corr.isna().all().all():\n",
    "            ax.set_xticks(range(len(target_quotes)))\n",
    "            ax.set_yticks(range(len(target_quotes)))\n",
    "            ax.set_xticklabels(target_quotes, fontsize=10)\n",
    "            ax.set_yticklabels(target_quotes, fontsize=10, rotation=0)\n",
    "            ax.tick_params(axis=\"x\", labelrotation=90)\n",
    "\n",
    "            for pos in range(len(target_quotes)+1):\n",
    "                ax.axhline(pos - 0.5, color=\"white\", linewidth=0.5)\n",
    "                ax.axvline(pos - 0.5, color=\"white\", linewidth=0.5)\n",
    "\n",
    "            ax.set_xlim(-0.5, len(target_quotes)-0.5)\n",
    "            ax.set_ylim(len(target_quotes)-0.5, -0.5)\n",
    "            continue\n",
    "\n",
    "        # Plot heatmap\n",
    "        sns.heatmap(\n",
    "            corr,\n",
    "            vmin=-1, vmax=1,\n",
    "            cmap=\"RdYlGn\",\n",
    "            annot=True,\n",
    "            fmt=\".2f\",\n",
    "            xticklabels=target_quotes,\n",
    "            yticklabels=target_quotes,\n",
    "            ax=ax,\n",
    "            cbar=False,\n",
    "            linewidths=0.5,\n",
    "            linecolor=\"white\"\n",
    "        )\n",
    "\n",
    "        ax.set_xticklabels(target_quotes, fontsize=10)\n",
    "        ax.set_yticklabels(target_quotes, fontsize=10)\n",
    "        ax.tick_params(axis=\"x\", labelrotation=90)\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.set_title(\"\")\n",
    "\n",
    "# Add titles for columns\n",
    "for j, year in enumerate(years):\n",
    "    axes[0, j].set_title(f\"Year: {year}\", fontsize=16)\n",
    "\n",
    "# Add row labels for bases\n",
    "for i, label in enumerate(row_labels):\n",
    "    ax0 = axes[i, 0]\n",
    "    ax0.set_ylabel(label, fontsize=14, rotation=90, labelpad=40)\n",
    "    ax0.yaxis.set_label_coords(-0.15, 0.5)\n",
    "    ax0.yaxis.label.set_rotation(90)\n",
    "\n",
    "plt.suptitle(\n",
    "    'Correlation Matrix of the Behavior of Quote Currencies',\n",
    "    fontweight='bold'\n",
    ")\n",
    "plt.tight_layout(rect=[0, 0, 0.90, 1])\n",
    "\n",
    "# Add colorbar\n",
    "norm = plt.Normalize(-1, 1)\n",
    "sm = plt.cm.ScalarMappable(cmap=\"RdYlGn\", norm=norm)\n",
    "sm.set_array([])\n",
    "cbar_ax = fig.add_axes([0.92, 0.1, 0.02, 0.8])\n",
    "fig.colorbar(sm, cax=cbar_ax)\n",
    "\n",
    "# Save the figure\n",
    "save_path = (\n",
    "    \"Figures/Correlation of Returns Across Three Random Base Currencies \"\n",
    "    \"Across Target Quote Pairs.png\"\n",
    ")\n",
    "plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved to:\", save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae35946d-327b-4435-a6b8-67f7d6bc0036",
   "metadata": {},
   "source": [
    "The code above was generated using ChatGPT. It took around a minute for the code to load.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"Figures/Correlation of Returns Across Three Random Base Currencies Across Target Quote Pairs.png\" />\n",
    "</div>\n",
    "\n",
    "**Figure 4.** Behavior of the quote currencies of selected base currencies.\n",
    "\n",
    "The correlation plots in Figure 4 describe the relationship between the returns of three random base coins (ADA, BTC, and ETH) and fixed quote currencies (BUSD, EUR, and USDT) throughout all years of the dataset. \n",
    "In connection with the previous column chart analysis, some cells within the correlation plots of years 2017, 2018, and 2019 are left empty because the expansion of Binance assets did not occur until 2019. \n",
    "Given that all of the correlation cells are closer to the value of 1.00 (colored by a shade of green), the value of the base coin's return gives a small difference when there is a change in the quote currency. \n",
    "This is clearly shown in the correlation plots of BTC and ETH in years 2021 and 2022 wherein all the correlation values lie within the range of 0.95 to 1.00. \n",
    "For ADA, some explanations for its relatively lower correlations could be that:\n",
    "1. The market of the base coin has not matured enough yet. This is evident when the correlation plots of the base coins in earlier years are observed. Lesser users engaging with the specific coin means lesser data for correlation value, therefore the values in consideration are more sensitive to randomness. \n",
    "2. Difference in macroeconomic conditions. More specifically, the value of EUR is tied to the real world currency of Europe, the *Euro*. This means that the value of any cryptocurrency tied to EUR could transitively be affected by changes in the Euro, which could cause the return behavior to deivate from those tied to US currencies (USDT and BUSD).\n",
    "\n",
    "Given that most of the correlation plots show similar results, the return values of the base currency do not have a strong dependency on the quote currency. Differing quote currencies usually have the same behavior when under the same base currency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d9853-ef25-4992-bdc2-f298fc1b97b2",
   "metadata": {},
   "source": [
    "<div style=\"color: #270f47; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "## Correlation of Returns Across Base Currencies for each Quote\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4331d540-cb90-49a8-b866-11f061ae25f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T13:54:36.904001Z",
     "iopub.status.busy": "2025-11-24T13:54:36.903772Z",
     "iopub.status.idle": "2025-11-24T13:54:44.184093Z",
     "shell.execute_reply": "2025-11-24T13:54:44.182544Z",
     "shell.execute_reply.started": "2025-11-24T13:54:36.903982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved flipped correlation figure to: Figures/Correlation of Returns Across Three Random Base Currencies Within Each Target Quote.png\n"
     ]
    }
   ],
   "source": [
    "# Labels for rows based on target quotes\n",
    "quote_row_labels = [\n",
    "    f\"Quote 1: {target_quotes[0]}\",\n",
    "    f\"Quote 2: {target_quotes[1]}\",\n",
    "    f\"Quote 3: {target_quotes[2]}\",\n",
    "]\n",
    "\n",
    "# Set up figure dimensions\n",
    "n_rows_2 = len(target_quotes)\n",
    "n_cols_2 = len(years)\n",
    "\n",
    "fig2, axes2 = plt.subplots(\n",
    "    nrows=n_rows_2,\n",
    "    ncols=n_cols_2,\n",
    "    figsize=(4 * n_cols_2, 4 * n_rows_2),\n",
    "    squeeze=False,\n",
    "    sharex=True,\n",
    "    sharey=True\n",
    ")\n",
    "\n",
    "# Loop over quotes and years to plot correlation heatmaps\n",
    "for i, quote in enumerate(target_quotes):  # row = quote\n",
    "    for j, year in enumerate(years):       # col = year\n",
    "        ax = axes2[i, j]\n",
    "\n",
    "        sub = pdf[\n",
    "            (pdf[\"quote_currency\"] == quote) &\n",
    "            (pdf[\"year\"] == year) &\n",
    "            (pdf[\"base_currency\"].isin(base_by_row))\n",
    "        ]\n",
    "\n",
    "        # If no data, create empty grid\n",
    "        if sub.empty:\n",
    "            ax.set_xticks(range(len(base_by_row)))\n",
    "            ax.set_yticks(range(len(base_by_row)))\n",
    "            ax.set_xticklabels(base_by_row, fontsize=10, rotation=90)\n",
    "            ax.set_yticklabels(base_by_row, fontsize=10, rotation=0)\n",
    "\n",
    "            for pos in range(len(base_by_row) + 1):\n",
    "                ax.axhline(pos - 0.5, color=\"white\", linewidth=0.5)\n",
    "                ax.axvline(pos - 0.5, color=\"white\", linewidth=0.5)\n",
    "\n",
    "            ax.set_xlim(-0.5, len(base_by_row) - 0.5)\n",
    "            ax.set_ylim(len(base_by_row) - 0.5, -0.5)\n",
    "\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_visible(False)\n",
    "            continue\n",
    "\n",
    "        # Pivot data for correlation calculation\n",
    "        wide = sub.pivot_table(\n",
    "            index=\"open_time\",\n",
    "            columns=\"base_currency\",\n",
    "            values=\"return\"\n",
    "        ).reindex(columns=base_by_row)\n",
    "\n",
    "        corr = wide.corr()\n",
    "\n",
    "        # If correlation is all NaN, draw empty grid\n",
    "        if corr.isna().all().all():\n",
    "            ax.set_xticks(range(len(base_by_row)))\n",
    "            ax.set_yticks(range(len(base_by_row)))\n",
    "            ax.set_xticklabels(base_by_row, fontsize=10, rotation=90)\n",
    "            ax.set_yticklabels(base_by_row, fontsize=10, rotation=0)\n",
    "\n",
    "            for pos in range(len(base_by_row) + 1):\n",
    "                ax.axhline(pos - 0.5, color=\"white\", linewidth=0.5)\n",
    "                ax.axvline(pos - 0.5, color=\"white\", linewidth=0.5)\n",
    "\n",
    "            ax.set_xlim(-0.5, len(base_by_row) - 0.5)\n",
    "            ax.set_ylim(len(base_by_row) - 0.5, -0.5)\n",
    "            continue\n",
    "\n",
    "        # Plot heatmap\n",
    "        sns.heatmap(\n",
    "            corr,\n",
    "            vmin=-1,\n",
    "            vmax=1,\n",
    "            cmap=\"RdYlGn\",\n",
    "            annot=True,\n",
    "            fmt=\".2f\",\n",
    "            xticklabels=base_by_row,\n",
    "            yticklabels=base_by_row,\n",
    "            ax=ax,\n",
    "            cbar=False,\n",
    "            linewidths=0.5,\n",
    "            linecolor=\"white\"\n",
    "        )\n",
    "\n",
    "        ax.tick_params(axis=\"y\")\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.set_title(\"\")\n",
    "\n",
    "# Add year titles to top row\n",
    "for j, year in enumerate(years):\n",
    "    axes2[0, j].set_title(f\"Year: {year}\", fontsize=14)\n",
    "\n",
    "# Rotate y-axis labels\n",
    "for i in range(n_rows_2):\n",
    "    axes2[i, 0].tick_params(axis=\"y\", labelrotation=90)\n",
    "\n",
    "# Add row labels for quotes\n",
    "for i, label in enumerate(quote_row_labels):\n",
    "    ax0 = axes2[i, 0]\n",
    "\n",
    "    # If this row has no heatmap, turn on axis but hide frame\n",
    "    if not axes2[i, 0].has_data():\n",
    "        ax0.set_axis_on()\n",
    "        ax0.set_frame_on(False)\n",
    "    else:\n",
    "        # Heatmap axis  keep base ticks\n",
    "        ax0.tick_params(axis='y', labelsize=12)\n",
    "\n",
    "    # Set quote label\n",
    "    ax0.set_ylabel(label, fontsize=14, rotation=90, labelpad=40)\n",
    "    ax0.yaxis.set_label_coords(-0.10, 0.5)\n",
    "\n",
    "plt.suptitle(\n",
    "    'Correlation Matrix of the Behavior of Base Currencies',\n",
    "    fontweight='bold'\n",
    ")\n",
    "plt.tight_layout(rect=[0, 0, 0.90, 1])\n",
    "\n",
    "# Add colorbar\n",
    "norm2 = plt.Normalize(-1, 1)\n",
    "sm2 = plt.cm.ScalarMappable(cmap=\"RdYlGn\", norm=norm2)\n",
    "sm2.set_array([])\n",
    "cbar_ax2 = fig2.add_axes([0.92, 0.1, 0.02, 0.8])\n",
    "fig2.colorbar(sm2, cax=cbar_ax2)\n",
    "\n",
    "# Save the figure\n",
    "save_path2 = (\n",
    "    \"Figures/Correlation of Returns Across Three Random Base Currencies \"\n",
    "    \"Within Each Target Quote.png\"\n",
    ")\n",
    "plt.savefig(save_path2, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved flipped correlation figure to:\", save_path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c294a4a-8d3e-43dd-b331-c7026a04d24c",
   "metadata": {},
   "source": [
    "The code above was generated using ChatGPT. It took around 7 seconds to load.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"Figures/Correlation of Returns Across Three Random Base Currencies Within Each Target Quote.png\" />\n",
    "</div>\n",
    "\n",
    "**Figure 5.** Behavior of the base currencies relative to the quote currencies.\n",
    "\n",
    "In comparison to Figure 4, the correlation plots in Figure 5 describe how the base currencies move relative to each other when paired with the same quote currency. \n",
    "First, it could be noticed that there is a slow increase in the correlations of all the base currencies as the years pass. \n",
    "As these cryptocurrency markets mature, the behavior of the base currencies becomes more similar as they gain more user activity (liquidity).\n",
    "Looking closer into the plots, it could be noticed that across all quote currencies, the correlation between BTC and ETH is stronger than that of BTC and ADA. \n",
    "What this hints is that the movement of ADA deviates somewhat by differing/broader market factors, but the overall movement of these three base currencies is the same nonetheless. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a48b8ae-84a0-4d54-bf32-23492389471a",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #270f47; color: #eed47c; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "# VI. Data Processing\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c99bff-d4f9-4675-821e-2b8a4be3d37f",
   "metadata": {},
   "source": [
    "In this portion, we are trying to fulfill our goals where we compare volatility, price stability, and trading activity patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1afa2c-3a4d-4421-8a19-f701e6c7b335",
   "metadata": {},
   "source": [
    "<div style=\"color: #270f47; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "## Volatility Comparison\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c503bdfe-2346-416f-96d7-bedf0074ea63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T13:22:29.142797Z",
     "iopub.status.busy": "2025-11-24T13:22:29.142553Z",
     "iopub.status.idle": "2025-11-24T13:23:26.415793Z",
     "shell.execute_reply": "2025-11-24T13:23:26.414757Z",
     "shell.execute_reply.started": "2025-11-24T13:22:29.142777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: Figures/annual_volatility_by_year.png\n",
      "Saved: Figures/rolling_volatility_examples.png\n"
     ]
    }
   ],
   "source": [
    "def calculate_volatility_measures(\n",
    "    spark_df,\n",
    "    output_dir='Figures',\n",
    "    rolling_window_days=30,\n",
    "    annualization_factor=np.sqrt(365),\n",
    "    min_rolling_obs=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculate daily log returns and volatility measures (annualized and \n",
    "    rolling) for each base-quote pair in a Spark DataFrame. Generates and \n",
    "    saves plots for annual and rolling volatilities.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Extract date from open_time\n",
    "    spark_daily = spark_df.withColumn('date', to_date('open_time'))\n",
    "\n",
    "    # Keep only last observation per day per base-quote\n",
    "    rn_window = (\n",
    "        Window.partitionBy('base_currency', 'quote_currency', 'date')\n",
    "        .orderBy(F.col('open_time').desc())\n",
    "    )\n",
    "    spark_daily = (\n",
    "        spark_daily\n",
    "        .withColumn('_rn', row_number().over(rn_window))\n",
    "        .filter(col('_rn') == 1)\n",
    "        .drop('_rn')\n",
    "    )\n",
    "\n",
    "    # Lag previous close to calculate log returns\n",
    "    lag_window = Window.partitionBy(\n",
    "        'base_currency', 'quote_currency'\n",
    "    ).orderBy('date')\n",
    "    spark_daily = (\n",
    "        spark_daily\n",
    "        .withColumn('prev_close', F.lag('close').over(lag_window))\n",
    "        .withColumn(\n",
    "            'log_return',\n",
    "            F.when(\n",
    "                F.col('prev_close').isNotNull(),\n",
    "                F.log(col('close') / col('prev_close'))\n",
    "            ).otherwise(F.lit(None)),\n",
    "        )\n",
    "    )\n",
    "    spark_daily = spark_daily.filter(col('log_return').isNotNull())\n",
    "    spark_daily = spark_daily.withColumn('year', F.year(F.col('date')))\n",
    "\n",
    "    # Compute annual volatility per base-quote\n",
    "    annual_vol_df = (\n",
    "        spark_daily\n",
    "        .groupBy('base_currency', 'quote_currency', 'year', 'classification')\n",
    "        .agg(\n",
    "            (F.stddev('log_return') * F.lit(annualization_factor))\n",
    "            .alias('annual_volatility'),\n",
    "            F.count('log_return').alias('n_days')\n",
    "        )\n",
    "        .filter(col('annual_volatility').isNotNull())\n",
    "        .orderBy('base_currency', 'quote_currency', 'year')\n",
    "    )\n",
    "\n",
    "    # Compute rolling volatility\n",
    "    rolling_w = (\n",
    "        Window.partitionBy('base_currency', 'quote_currency')\n",
    "        .orderBy('date')\n",
    "        .rowsBetween(-(rolling_window_days - 1), 0)\n",
    "    )\n",
    "    spark_daily = spark_daily.withColumn(\n",
    "        'rolling_std', F.stddev('log_return').over(rolling_w)\n",
    "    )\n",
    "    spark_daily = spark_daily.withColumn(\n",
    "        'rolling_vol_annualized',\n",
    "        F.when(\n",
    "            F.col('rolling_std').isNotNull(),\n",
    "            F.col('rolling_std') * F.lit(annualization_factor),\n",
    "        ).otherwise(None)\n",
    "    )\n",
    "\n",
    "    # Count observations in rolling window\n",
    "    count_w = rolling_w\n",
    "    spark_daily = spark_daily.withColumn(\n",
    "        'rolling_count', F.count('log_return').over(count_w)\n",
    "    )\n",
    "    spark_daily = spark_daily.withColumn(\n",
    "        'rolling_vol_annualized',\n",
    "        F.when(\n",
    "            col('rolling_count') >= min_rolling_obs, col('rolling_vol_annualized')\n",
    "        )\n",
    "        .otherwise(F.lit(None))\n",
    "    )\n",
    "\n",
    "    # Convert to pandas for plotting\n",
    "    annual_vol_pd = annual_vol_df.toPandas()\n",
    "    rolling_pd = (\n",
    "        spark_daily\n",
    "        .select(\n",
    "            'base_currency',\n",
    "            'quote_currency',\n",
    "            'date',\n",
    "            'rolling_vol_annualized',\n",
    "            'rolling_count',\n",
    "            'classification'\n",
    "        )\n",
    "        .toPandas()\n",
    "    )\n",
    "\n",
    "    # Plot annual volatility per base currency\n",
    "    try:\n",
    "        base_list = sorted(annual_vol_pd['base_currency'].unique())\n",
    "        n_plots = min(len(base_list), 10)\n",
    "        cols = 5\n",
    "        rows = math.ceil(n_plots / cols)\n",
    "        fig, axes = plt.subplots(\n",
    "            rows, cols, figsize=(cols * 5, rows * 4), sharex=True, sharey=True\n",
    "        )\n",
    "        axes = axes.flatten()\n",
    "        all_years = sorted(annual_vol_pd['year'].unique())\n",
    "\n",
    "        if len(all_years) == 0:\n",
    "            print(\"No annual data to plot.\")\n",
    "        else:\n",
    "            for i, base in enumerate(base_list[:n_plots]):\n",
    "                ax = axes[i]\n",
    "                bdf = annual_vol_pd[annual_vol_pd['base_currency'] == base]\n",
    "                for quote in sorted(bdf['quote_currency'].unique()):\n",
    "                    qdf = bdf[bdf['quote_currency'] == quote]\n",
    "                    ax.plot(\n",
    "                        qdf['year'], qdf['annual_volatility'], \n",
    "                        marker='o', label=quote\n",
    "                    )\n",
    "                ax.set_title(f'{base} as Base Currency')\n",
    "                ax.set_xticks(all_years)\n",
    "                ax.set_ylim(0, 3)\n",
    "                ax.grid(alpha=0.3)\n",
    "                ax.legend(fontsize=8)\n",
    "\n",
    "            # Hide unused axes\n",
    "            for j in range(n_plots, len(axes)):\n",
    "                axes[j].set_visible(False)\n",
    "\n",
    "            plt.suptitle(\n",
    "                'Annual Volatility by Base Currency (per quote)',\n",
    "                fontsize=14, fontweight='bold', y=0.98\n",
    "            )\n",
    "            fig.supylabel('Annual Volatility (Standard Deviation)')\n",
    "            fig.supxlabel('Years')\n",
    "            plt.tight_layout(rect=[0.015, 0.01, 1, 0.97])\n",
    "            out1 = os.path.join(output_dir, 'annual_volatility_by_year.png')\n",
    "            plt.savefig(out1, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(\"Saved:\", out1)\n",
    "    except Exception as e:\n",
    "        print(\"Plotting annual volatility failed:\", e)\n",
    "\n",
    "    # Plot rolling volatility examples for top base-quote pairs\n",
    "    try:\n",
    "        counts = (\n",
    "            rolling_pd.groupby(['base_currency', 'quote_currency'])\n",
    "            .size()\n",
    "            .reset_index(name='n')\n",
    "        )\n",
    "        top_series = counts.sort_values('n', ascending=False).head(4)\n",
    "        fig, axes = plt.subplots(len(top_series), 1, figsize=(12, 3 * len(top_series)))\n",
    "        if len(top_series) == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        for ax, (_, row) in zip(axes, top_series.iterrows()):\n",
    "            base = row['base_currency']\n",
    "            quote = row['quote_currency']\n",
    "            ser = rolling_pd[\n",
    "                (rolling_pd['base_currency'] == base) &\n",
    "                (rolling_pd['quote_currency'] == quote)\n",
    "            ].sort_values('date')\n",
    "            ax.plot(\n",
    "                ser['date'], ser['rolling_vol_annualized'], marker='.', linewidth=1\n",
    "            )\n",
    "            ax.set_title(\n",
    "                f'Rolling {rolling_window_days}-day annualized vol: {base}-{quote}'\n",
    "            )\n",
    "            ax.set_ylabel('Annualized vol')\n",
    "            ax.set_xlabel('Date')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        out2 = os.path.join(output_dir, 'rolling_volatility_examples.png')\n",
    "        plt.savefig(out2, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"Saved:\", out2)\n",
    "    except Exception as e:\n",
    "        print(\"Plotting rolling volatility failed:\", e)\n",
    "\n",
    "    return annual_vol_pd, rolling_pd\n",
    "\n",
    "\n",
    "# Run the function\n",
    "annual_volatility_df, rolling_volatility_df = calculate_volatility_measures(\n",
    "    spark_df\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d00a56-dccf-4445-8336-29a1c18203b8",
   "metadata": {},
   "source": [
    "The code above was generated with ChatGPT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd29975-c35c-43dc-ad93-9c96d5465e5a",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"Figures/annual_volatility_by_year.png\" />\n",
    "</div>\n",
    "\n",
    "**Figure 6.** The annual volatility of each quote currency per base currency for every year.\n",
    "\n",
    "Figure 6 above shows that the annual volatility for each base and quote currency pair per year.\n",
    "To recall, a base currency are the available cryptocurrencies you can invest in.\n",
    "A few popular examples are Bitcoin, Dogecoin, and even Hawk Tuah coin.\n",
    "A quote currency is a way to value the base currency.\n",
    "Annual volatility was chosen for computational efficiency since we only want to compare a per-year basis.\n",
    "\n",
    "The annual volatility was calculated by getting the standard deviation of daily log returns and scaling it by the square root of 365.\n",
    "This is a way to measure risk and to see how volatile each cryptocurrency pair has been over time.\n",
    "Higher volatility values indicated greater price fluctuations and higher risk. \n",
    "Lower values suggest more stable price behavior.\n",
    "The plot reveals that some currencies maintain relatively consistent volatility across years, while others show significant spikes during certain periods, potentially corresponding to market events, adoption phases, or broader economic conditions affecting the cryptocurrency markets.\n",
    "\n",
    "In terms of different quote currencies, it shows that upon introduction, there is a significant difference in terms of volatility.\n",
    "Usually, when they are newly introduced, there is less volatility compared to the existing quote currencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0fd67e-1221-4524-9ecb-7b69aaf34a9d",
   "metadata": {},
   "source": [
    "<div style=\"color: #270f47; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "## Volume-Volatility Relationship\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b6484d1-9cc9-4d51-a64d-67a306f76c7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T13:23:26.417121Z",
     "iopub.status.busy": "2025-11-24T13:23:26.416886Z",
     "iopub.status.idle": "2025-11-24T13:23:55.437879Z",
     "shell.execute_reply": "2025-11-24T13:23:55.436891Z",
     "shell.execute_reply.started": "2025-11-24T13:23:26.417101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved to: Figures/volume_return_3x3.png\n"
     ]
    }
   ],
   "source": [
    "def analyze_volume_volatility(spark_df, output_dir='Figures', randomseed=42):\n",
    "    \"\"\"\n",
    "    Analyze volumereturn relationships for randomly selected base and quote\n",
    "    currencies and generate a 3x3 grid of scatter plots with shared axes.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Get date from timestamp\n",
    "    spark_daily = spark_df.withColumn('date', to_date('open_time'))\n",
    "\n",
    "    # Keep only the last observation per day for each base-quote pair\n",
    "    rn_window = (\n",
    "        Window.partitionBy('base_currency', 'quote_currency', 'date')\n",
    "        .orderBy(F.col('open_time').desc())\n",
    "    )\n",
    "\n",
    "    spark_daily = (\n",
    "        spark_daily\n",
    "        .withColumn('_rn', row_number().over(rn_window))\n",
    "        .filter(col('_rn') == 1)\n",
    "        .drop('_rn')\n",
    "    )\n",
    "\n",
    "    # Compute daily returns\n",
    "    lag_window = (\n",
    "        Window.partitionBy('base_currency', 'quote_currency')\n",
    "        .orderBy('date')\n",
    "    )\n",
    "\n",
    "    spark_daily = (\n",
    "        spark_daily\n",
    "        .withColumn('prev_close', F.lag('close').over(lag_window))\n",
    "        .withColumn(\n",
    "            'return',\n",
    "            F.when(\n",
    "                F.col('prev_close').isNotNull(),\n",
    "                (col('close') - col('prev_close')) / col('prev_close')\n",
    "            ).otherwise(None)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Filter out rows where return is null\n",
    "    spark_daily = spark_daily.filter(col('return').isNotNull())\n",
    "\n",
    "    # Convert to pandas for plotting\n",
    "    volume_volatility_df = spark_daily.select(\n",
    "        'base_currency', 'quote_currency', 'date', 'volume', 'return'\n",
    "    ).toPandas()\n",
    "\n",
    "    # Randomly select 3 quotes and 3 bases for plotting\n",
    "    rng = np.random.default_rng(randomseed)\n",
    "    quotes = volume_volatility_df['quote_currency'].unique()\n",
    "    selected_quotes = rng.choice(\n",
    "        quotes,\n",
    "        size=min(3, len(quotes)),\n",
    "        replace=False\n",
    "    )\n",
    "    bases = volume_volatility_df['base_currency'].unique()\n",
    "    selected_bases = rng.choice(\n",
    "        bases,\n",
    "        size=min(3, len(bases)),\n",
    "        replace=False\n",
    "    )\n",
    "\n",
    "    # plotting\n",
    "    fig, axes = plt.subplots(\n",
    "        3, 3,\n",
    "        figsize=(18, 14),\n",
    "        sharex=True,\n",
    "        sharey=True\n",
    "    )\n",
    "\n",
    "    for i, base in enumerate(selected_bases):\n",
    "        for j, quote in enumerate(selected_quotes):\n",
    "            ax = axes[i, j]\n",
    "\n",
    "            data = volume_volatility_df[\n",
    "                (volume_volatility_df['base_currency'] == base)\n",
    "                & (volume_volatility_df['quote_currency'] == quote)\n",
    "            ]\n",
    "\n",
    "            if data.empty:\n",
    "                ax.text(0.5, 0.5, \"No data\", ha='center', va='center')\n",
    "                ax.set_axis_off()\n",
    "                continue\n",
    "\n",
    "            returns = data['return']\n",
    "            volumes = data['volume']\n",
    "\n",
    "            ax.scatter(volumes, returns, alpha=0.6, s=10, c='#bba9de')\n",
    "            ax.set_ylim(-1, 1)\n",
    "            ax.set_xlim(0, 10000)\n",
    "\n",
    "            if i == 0:\n",
    "                ax.set_title(f\"Quote Currency: {quote}\")\n",
    "\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(f\"Base Currency: {base}\")\n",
    "\n",
    "            corr, pval = spearmanr(volumes, returns)\n",
    "\n",
    "            ax.text(\n",
    "                0.05,\n",
    "                0.95,\n",
    "                f'r={corr:.2f}\\np={pval:.3f}',\n",
    "                transform=ax.transAxes,\n",
    "                va='top',\n",
    "                fontsize=9,\n",
    "                bbox=dict(\n",
    "                    boxstyle='round',\n",
    "                    facecolor='wheat',\n",
    "                    alpha=0.75\n",
    "                )\n",
    "            )\n",
    "\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "    fig.text(0.5, 0.04, \"Daily Volume\", ha='center', fontsize=13)\n",
    "    \n",
    "    plt.suptitle(\n",
    "        \"Volume vs Return Across Selected Base and Quote Currencies\",\n",
    "        fontsize=18,\n",
    "        fontweight='bold'\n",
    "    )\n",
    "    fig.supylabel('Daily Returns', x=0.01)\n",
    "\n",
    "    plt.tight_layout(rect=[0.05, 0.05, 1, 0.96])\n",
    "\n",
    "    out_path = os.path.join(output_dir, \"volume_return_3x3.png\")\n",
    "    plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Figure saved to: {out_path}\")\n",
    "\n",
    "    return volume_volatility_df\n",
    "\n",
    "volume_volatility_df = analyze_volume_volatility(spark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628bc394-bc1e-4b18-8b54-b1506eb644a2",
   "metadata": {},
   "source": [
    "The code above was generated with ChatGPT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8f7f3b-66d8-4a73-8822-988e1fafbee8",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"Figures/volume_return_3x3.png\" />\n",
    "</div>\n",
    "\n",
    "**Figure 7.** The annual volatility of each quote currency per base currency for every year.\n",
    "                                                                            \n",
    "As seen in Figure 7, the plots of volume and returns, it seems that the volume of stocks has no direct correlation to its returns. \n",
    "This is also consistent for different base and quote currency pairs. \n",
    "However, it seems that there is a set trading patten for different base currencies. \n",
    "For example, for the LTC base cryptocurrency, usually people trade it in lower daily volumes, but there are varying returns.\n",
    "This could suggest:\n",
    "1. Lower market participation for LTC pairs\n",
    "2. Different trader behavior or investment time horizons for this base currency\n",
    "3. Potential for higher volatility due to thinner markets\n",
    "\n",
    "The volume patterns suggest that there are cryptocurrencies that could have unique market microstructure characteristics that persist regardless of the quote currency being traded against."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752afff5-db6d-4eb8-81c9-d7174cf33309",
   "metadata": {},
   "source": [
    "<div style=\"color: #270f47; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "## Hourly Trading Trends in Terms of Volume\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a086f38-db26-4b04-9138-eff56f35651b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T15:29:18.009355Z",
     "iopub.status.busy": "2025-11-24T15:29:18.008655Z",
     "iopub.status.idle": "2025-11-24T15:29:26.372610Z",
     "shell.execute_reply": "2025-11-24T15:29:26.371648Z",
     "shell.execute_reply.started": "2025-11-24T15:29:18.009283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved average volume heatmap to: Figures/average_volume_per_hour_base_quote_pair.png\n"
     ]
    }
   ],
   "source": [
    "df_hr = (\n",
    "    spark_df\n",
    "    .withColumn(\"hour_of_day\", F.hour(\"open_time\"))\n",
    "    .withColumn(\n",
    "        \"pair\",\n",
    "        F.concat_ws(\"-\", \"base_currency\", \"quote_currency\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Compute average volume per hour per pair\n",
    "vol_df_spark = (\n",
    "    df_hr\n",
    "    .groupBy(\"pair\", \"hour_of_day\")\n",
    "    .agg(F.avg(\"volume\").alias(\"avg_volume\"))\n",
    ")\n",
    "\n",
    "# Convert to pandas\n",
    "pdf = vol_df_spark.toPandas()\n",
    "\n",
    "# Pivot into heatmap matrix\n",
    "heatmap_df = pdf.pivot(\n",
    "    index=\"pair\",\n",
    "    columns=\"hour_of_day\",\n",
    "    values=\"avg_volume\",\n",
    ")\n",
    "\n",
    "all_hours = list(range(24))\n",
    "for hour in all_hours:\n",
    "    if hour not in heatmap_df.columns:\n",
    "        heatmap_df[hour] = np.nan\n",
    "\n",
    "# Order columns and rows\n",
    "heatmap_df = heatmap_df[all_hours].sort_index()\n",
    "\n",
    "# Log-scale (volume varies a lot across pairs)\n",
    "heatmap_log = np.log1p(heatmap_df)\n",
    "\n",
    "# Heatmap\n",
    "colors = [\"red\", \"white\", \"green\"]\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\n",
    "    \"vol_cmap\",\n",
    "    colors,\n",
    "    N=256,\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18, 12))\n",
    "\n",
    "sns.heatmap(\n",
    "    heatmap_log,\n",
    "    cmap=custom_cmap,\n",
    "    linewidths=0.4,\n",
    "    cbar_kws={\"label\": \"Average Volume (log-scaled)\"},\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "title = (\n",
    "    \"Average Volume per Hour for Each BaseQuote Pair\"\n",
    ")\n",
    "ax.set_title(title)\n",
    "ax.set_xlabel(\"Hour of Day (023)\")\n",
    "ax.set_ylabel(\"BaseQuote Pair\")\n",
    "\n",
    "save_path = \"Figures/average_volume_per_hour_base_quote_pair.png\"\n",
    "fig.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"Saved average volume heatmap to:\", save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6546c6d7-c001-4f4d-941a-da17b37533f6",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"Figures/average_volume_per_hour_base_quote_pair.png\" />\n",
    "</div>\n",
    "\n",
    "**Figure 8.** Heatmap of the average volume traded per base-quote pair for various hours of the day\n",
    "\n",
    "Figure 8 reveals that for nearly every base asset (like BTC, ETH, ADA), the trading pairs with USDT consistently show the highest average volume, indicating that Tether is the dominant stablecoin and preferred trading vehicle for these cryptocurrencies. \n",
    "Pairs quoted in EUR generally form a middle tier of volume, demonstrating significant European market participation, but not at the level of the global USDT-based markets. \n",
    "The BUSD-quoted pairs typically show the lowest volume among the three, reflecting its diminished role and lower trader adoption following regulatory pressures. This three-tiered volume hierarchy (USDT > EUR > BUSD) is remarkably consistent across all the different base assets, from major ones like Bitcoin and Ethereum to altcoins like DOGE and EOS. \n",
    "Furthermore, the trading activity for all pairs follows a similar cyclical pattern throughout the day, but the USDT pairs' lines are elevated, meaning they drive the overall market's rhythm from a position of much higher liquidity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49af6c18-6470-4a5d-b575-ea7a3dc4e488",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #270f47; color: #eed47c; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "# VII. Results and Discussion\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7c19ba-60bb-411a-8853-48a8038dd7c7",
   "metadata": {},
   "source": [
    "The analysis we've done on base and quote currencies reveal interesting patterns in market structure and liquidity over time. \n",
    "Figure 3 shows that there was gradual diversification in the Binance market.\n",
    "Initially, USDT dominated as a common quote currency, but the emergence of BUSD in 2019 and EUR in 2020 reflects key market developments including the rise of Binance's Launchpad projects. \n",
    "This diversification corresponds with increased maturity in the cryptocurrency ecosystem, as more base currencies become accessible under multiple quote currencies. \n",
    "Correlation analyses (Figures 4 and 5) further suggest that the returns of base currencies are largely independent of the quote currency used, with high correlations observed for major coins like BTC and ETH. \n",
    "Notably, ADA exhibits lower correlations in early years, likely reflecting lower liquidity and sensitivity to broader macroeconomic factors such as fluctuations in the Euro, demonstrating how market maturity and external economic conditions can influence individual assets.\n",
    "\n",
    "Volatility and trading patterns also provide additional insights into market behavior (Figures 6 and 7). \n",
    "While some base currencies maintain stable annual volatility, others experience pronounced spikes, likely due to market events or adoption cycles. \n",
    "Newly introduced quote currencies initially show lower volatility, suggesting gradual integration into trading activity. \n",
    "Additionally, trading volume does not consistently predict returns, as seen in LTC, which experiences low daily volume but variable returns. \n",
    "This indicates unique market microstructure characteristics for certain cryptocurrencies, including variations in trader behavior, liquidity, and market participation. \n",
    "\n",
    "Figure 8 adds another important dimension by examining trading activity throughout the day. \n",
    "Across nearly all base assets (e.g., BTC, ETH, ADA), pairs quoted in USDT consistently show the highest average volume, indicating that Tether is the dominant stablecoin and preferred trading vehicle. \n",
    "EUR-quoted pairs form a middle tier, reflecting significant but regionally concentrated market participation, while BUSD pairs typically show the lowest volume, consistent with regulatory pressures and lower adoption. \n",
    "Furthermore, trading activity follows a similar cyclical pattern across all pairs, but USDT pairs dominate the rhythm of the market due to their higher liquidity. \n",
    "\n",
    "For first-time traders, these insights offer practical guidance:\n",
    "1. The returns of major cryptocurrencies like BTC and ETH are largely independent of the quote currency, meaning the choice of quote currency is less critical for these assets.\n",
    "2. Less established coins, such as ADA, display lower correlations and greater sensitivity to macroeconomic conditions, which may introduce higher risk.\n",
    "3. Recognizing differences in volatility and volume across base-quote pairs can help first-time traders select cryptocurrency pairs aligned with their risk tolerance and liquidity preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf7c135-de61-4cab-89dc-af6dbbf3b710",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #270f47; color: #eed47c; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "# VIII. Conclusion and Recommendations\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59dfa14-02ab-4501-9541-cbb1b4f84101",
   "metadata": {},
   "source": [
    "<div style=\"color: #270f47; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e44879-828e-4301-8f9a-709e718649a8",
   "metadata": {},
   "source": [
    "To summarize our report, we can say that data-drive trading in Binance has now been made easier from our findings.\n",
    "Major base currencies such as BTC and ETH demonstrate high return correlations across different quote currencies (USDT, BUSD, EUR), indicating that their performance is largely independent of the quote currency chosen. This suggests that first-time traders focusing on these established assets do not need to be overly concerned about which quote currency to select, as returns are generally consistent.\n",
    "\n",
    "In contrast, less established base currencies, like ADA, show lower correlations, especially in the earlier years of trading.\n",
    "This reflects lower liquidity, greater sensitivity to macroeconomic factors (e.g., fluctuations in the Euro), and higher exposure to market-specific dynamics. \n",
    "Volatility analysis further reveals that some cryptocurrencies maintain stable annual volatility, while others experience pronounced spikes due to market events or adoption cycles. \n",
    "Newly introduced quote currencies generally exhibit lower initial volatility, indicating gradual integration into trading activity. \n",
    "Moreover, trading volume does not consistently predict returns, as observed with LTC, which demonstrates low daily volumes but variable returns, reflecting unique market microstructure characteristics.\n",
    "\n",
    "Figure 8 reinforces the importance of liquidity, showing that USDT-quoted pairs consistently maintain the highest average trading volumes, while EUR pairs form a middle tier and BUSD pairs typically show the lowest volumes. \n",
    "This demonstrates how the choice of quote currency can influence trading efficiency and market participation.\n",
    "    \n",
    "Overall, for a first-time investor, this implies that **established cryptocurrencies paired with stable quote currencies offer relatively predictable risk and price behavior, whereas newer or less liquid assets carry higher uncertainty**. \n",
    "Understanding these differences would allow an investor to better align their portfolio with their risk tolerance, particularly in the choice of base and quote currency pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97667bd-4929-40aa-b0fc-e696d9d52be2",
   "metadata": {},
   "source": [
    "<div style=\"color: #270f47; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "## Suggested Framework for a Trading Strategy\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dc8220-d08c-4d3f-b48c-bbc4036d8d61",
   "metadata": {},
   "source": [
    "Based on what we observed, a simple approach to trading on Binance is to focus on how much prices move (volatility) and how active the market is (trading volume).\n",
    "\n",
    "For beginners, its safer to start with well-known cryptocurrencies like **BTC and ETH**, because their prices are more stable and behave similarly across different quote currencies.\n",
    "Also, they should consider using the **USDT** quote currency because it is more stable in value compared to the rest.\n",
    "For newer or less popular coins like **ADA**, its better to trade smaller amounts, since their prices can change more unpredictably.\n",
    "Furthermore, it seems that volatility usually increases after a quote currency is newly introduced, so first-time traders should be cautious when trading pairs with newly added quote currencies. \n",
    "This initial period of higher volatility means prices can swing more dramatically, which increases risk. \n",
    "Waiting until the market stabilizes and trading activity becomes more consistent can help reduce exposure to sudden price changes.\n",
    "\n",
    "A good practice is to watch when the price movements are calmer (lower volatility) before buying, to reduce the chance of big losses. \n",
    "You can also pay attention to trading activitytimes when more people are buying or selling can affect short-term price changes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6f0158-fc98-4260-9e4c-c50896b586d3",
   "metadata": {},
   "source": [
    "<div style=\"color: #270f47; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "## Recommendations\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f0d6bc-1821-4022-8ae8-6abe7bfb4b09",
   "metadata": {},
   "source": [
    "**Business Implications of Our Report**\n",
    "\n",
    "From a beginner trader's perspective, our study can serve as a data-driven guide for knowing how to navigate trading on the Binance platform.\n",
    "We clearly gave the differences on both the quote and base currency and how these can affect trading strategies. \n",
    "At the end, we were able to suggest a general framework for a trading strategy for the base-quote pairs we inspected in Binance.\n",
    "Although it is not a full trading strategy yet, it can be a guide for future work or for future traders.\n",
    "\n",
    "**Limitations of the Study**\n",
    "\n",
    "Due to time and computational constraints, we were not able to apply more advanced analyses on the different base and quote currency pairs.\n",
    "The data was also limited from 2017 until 2022. \n",
    "Hence, there is a chance that our analyses and predictions could be out of date.\n",
    "2022 was three years ago, so it is necessary that these tests be done again on more recent data, if available. \n",
    "Furthermore, we are clearly not as experienced in Binance as the average trader, so we were learning more about the platform along the way.\n",
    "There was a great learning curve that we had to address just to understand the terms that we discussed in this report.\n",
    "\n",
    "\n",
    "**Recommendations for Future Works**\n",
    "  \n",
    "Aligned to our limitations, we would highly recommend that the same analyses would be done on more recent data (if available).\n",
    "The last date in our dataset is in the year 2022, which is three years ago.\n",
    "Updated data is crucial for more accurate predictions and analyses on the behavior of the base and quote currency pairs on Binance.\n",
    "For future work, we'd recommend that people do topological data analysis (TDA) on the relationships between the different base and quote currency pairs.\n",
    "There is abundant data, and there are also a lot of currencies to choose from, so doing TDA would be a great way to visualize the latent relationships between the trading options available on binance. \n",
    "Furthermore, looking at the relationship between different base currencies with only available quote currency would be interesting to find out. \n",
    "Lastly, if we had more time, it would have been interesting to generate portfolios or a trading strategy at least for the different base-quote cryptocurrency pairs.\n",
    "This would have shown a great application of our learnings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9bf639-35c1-4499-96ae-b41335a6d2d7",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #270f47; color: #eed47c; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "# IX. References\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b605f88-f6eb-4e67-a7fb-d93a85948dd4",
   "metadata": {},
   "source": [
    "Binance. (2024).  [Binances seven-year journey: How Binance has changed the global crypto market]. Retrieved November 23, 2025, from https://www.binance.com/en/square/post/10784043486617\n",
    "\n",
    "Bitcoin.com. (2025). *Base and Quote Currency Explained*. Bitcoin.com Markets. https://markets.bitcoin.com/glossary/base-and-quote-currency\n",
    "\n",
    "BSO Editorial. (2023). *What is Binance?* BSO. https://www.bso.co/glossary/what-is-binance\n",
    "\n",
    "CryptoCrafted. (2025, May 2). *What is Cryptocurrency? The Ultimate Beginners Guide*. https://www.cryptocrafted.org/what-is-cryptocurrency\n",
    "\n",
    "Kraken Learn team. (2024, December 18). *Types of Cryptocurrency | Kraken*. https://www.kraken.com/learn/types-of-cryptocurrency\n",
    "\n",
    "MK Manoylov. (2024, August 30). *Beginners guide to cryptocurrency trading: different pair types*. The Block. https://www.theblock.co/learn/286332/beginners-guide-to-cryptocurrency-trading-different-pair-types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8853cb8b-da18-4a01-bcf1-11a5851a26ae",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #270f47; color: #eed47c; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "# X. Supplementary\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed377c61-2d93-4622-bce5-3ccfb4b7e33e",
   "metadata": {},
   "source": [
    "This portion just contains code that was created, but not really focused or talked about in the previous sections because it did not really help with carrying out the narrative of the report.\n",
    "\n",
    "**Disclaimer**: Some code in this section have been commented out because they took a long time to run on Jojie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bdd008-97b4-49b4-b84f-e01f7c03ace8",
   "metadata": {},
   "source": [
    "<div style=\"color: #270f47; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "## Total File Size\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7ffc87f-6f69-44fd-82ec-d82d8022ffcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T13:25:30.881826Z",
     "iopub.status.busy": "2025-11-24T13:25:30.881184Z",
     "iopub.status.idle": "2025-11-24T13:25:30.890897Z",
     "shell.execute_reply": "2025-11-24T13:25:30.889170Z",
     "shell.execute_reply.started": "2025-11-24T13:25:30.881770Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Getting the total size of files\n",
    "# total_size_bytes = 0\n",
    "\n",
    "# for base_currency in top_bases['base_currency']:\n",
    "#     for quote_currency in common_quotes:\n",
    "#         file_name = f\"{base_currency}-{quote_currency}.parquet\"\n",
    "#         if file_name in files:\n",
    "#             file_path = os.path.join(directory, file_name)\n",
    "#             total_size_bytes += os.path.getsize(file_path)\n",
    "\n",
    "# # Convert totals\n",
    "# total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "# total_size_gb = total_size_bytes / (1024 * 1024 * 1024)\n",
    "\n",
    "# # Calculate all-file totals\n",
    "# total_all_files_bytes = sum(os.path.getsize(os.path.join(directory, f)) for f in files)\n",
    "# total_all_files_gb = total_all_files_bytes / (1024 * 1024 * 1024)\n",
    "\n",
    "# # Output\n",
    "# print(f\"{'TOTAL (Top Bases + Common Quotes)':<35} {total_size_gb:>8.2f} GB ({total_size_mb:>.1f} MB)\")\n",
    "# print(f\"{'Percentage of All Data':<35} {(total_size_gb/total_all_files_gb)*100:>8.1f}%\")\n",
    "# print(f\"{'TOTAL (All Files)':<35} {total_all_files_gb:>8.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbe05fc-49c1-46f6-a25c-c358645e3f2b",
   "metadata": {},
   "source": [
    "<div style=\"color: #270f47; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "## Closing Prices per Base Currency per Year\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "621c684f-600e-4e02-9b2d-6c1fc06d40ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T13:25:30.893891Z",
     "iopub.status.busy": "2025-11-24T13:25:30.892693Z",
     "iopub.status.idle": "2025-11-24T13:25:30.902972Z",
     "shell.execute_reply": "2025-11-24T13:25:30.902097Z",
     "shell.execute_reply.started": "2025-11-24T13:25:30.893835Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Create output directory\n",
    "# output_dir = 'Figures'\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # Extract year from open_time and convert to date for better plotting\n",
    "# spark_df = spark_df.withColumn(\"year\", year(\"open_time\"))\n",
    "# spark_df = spark_df.withColumn(\"date\", to_date(\"open_time\"))\n",
    "\n",
    "# # Get unique years and base currencies\n",
    "# years = [row['year'] for row in spark_df.select(\"year\").distinct().collect()]\n",
    "# years.sort()\n",
    "# base_currencies = [\n",
    "#     row['base_currency'] for row in spark_df.select(\"base_currency\").distinct().collect()\n",
    "# ]\n",
    "\n",
    "# print(f\"Years available: {years}\")\n",
    "# print(f\"Base currencies: {base_currencies}\")\n",
    "\n",
    "# # For each base currency, create a figure with subplots for each year\n",
    "# for base_currency in base_currencies:\n",
    "#     print(f\"Processing {base_currency}...\")\n",
    "\n",
    "#     # Filter data for the current base currency\n",
    "#     currency_df = spark_df.filter(spark_df.base_currency == base_currency)\n",
    "\n",
    "#     # Create figure with 2 rows, 3 columns (for up to 6 years)\n",
    "#     fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "#     axes = axes.flatten()\n",
    "\n",
    "#     # Get available years for this currency and sort them\n",
    "#     currency_years = [row['year'] for row in currency_df.select(\"year\").distinct().collect()]\n",
    "#     currency_years.sort()\n",
    "\n",
    "#     # Plot each year in a separate subplot\n",
    "#     for i, year_val in enumerate(currency_years):\n",
    "#         if i >= 6:\n",
    "#             break\n",
    "\n",
    "#         # Filter data for the specific year\n",
    "#         year_data = currency_df.filter(currency_df.year == year_val)\n",
    "\n",
    "#         # Convert to pandas for plotting\n",
    "#         pandas_df = year_data.select(\"date\", \"close\", \"quote_currency\").toPandas()\n",
    "\n",
    "#         # Plot each quote currency as a separate line\n",
    "#         ax = axes[i]\n",
    "#         for quote_currency in pandas_df['quote_currency'].unique():\n",
    "#             quote_data = pandas_df[pandas_df['quote_currency'] == quote_currency]\n",
    "#             quote_data = quote_data.sort_values('date')\n",
    "#             ax.plot(\n",
    "#                 quote_data['date'],\n",
    "#                 quote_data['close'],\n",
    "#                 label=quote_currency,\n",
    "#                 linewidth=1,\n",
    "#                 alpha=0.7\n",
    "#             )\n",
    "\n",
    "#         ax.set_title(f'{base_currency} - {year_val}', fontsize=12, fontweight='bold')\n",
    "#         ax.set_xlabel('Date')\n",
    "#         ax.set_ylabel('Closing Price')\n",
    "#         ax.tick_params(axis='x', rotation=45)\n",
    "#         ax.legend(fontsize=8)\n",
    "#         ax.grid(True, alpha=0.3)\n",
    "\n",
    "#     # Hide empty subplots if we have fewer than 6 years\n",
    "#     for i in range(len(currency_years), 6):\n",
    "#         axes[i].set_visible(False)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "\n",
    "#     # Save the figure\n",
    "#     filename = os.path.join(output_dir, f'{base_currency}_volatility_comparison.png')\n",
    "#     plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "#     plt.close()\n",
    "\n",
    "#     print(f\"Saved: {filename}\")\n",
    "\n",
    "# print(\"All volatility comparison plots have been generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8968c876-e094-403a-a929-42cad1a5f447",
   "metadata": {},
   "source": [
    "<div style=\"color: #270f47; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "## Correlations of Returns to the Hours in a Trading Day\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d1af69-c13b-476a-be74-5a54f5dfd0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1) Per-candle return + hour + pair\n",
    "# w = Window.partitionBy(\"base_currency\", \"quote_currency\").orderBy(\"open_time\")\n",
    "\n",
    "# df_returns = (\n",
    "#     spark_df\n",
    "#     .withColumn(\"pair\", F.concat_ws(\"-\", \"base_currency\", \"quote_currency\"))\n",
    "#     .withColumn(\"hour_of_day\", F.hour(\"open_time\"))\n",
    "#     .withColumn(\"prev_close\", F.lag(\"close\").over(w))\n",
    "#     .filter(F.col(\"prev_close\").isNotNull())\n",
    "#     .withColumn(\"ret\",\n",
    "#                 (F.col(\"close\") - F.col(\"prev_close\")) / F.col(\"prev_close\"))\n",
    "#     .select(\"pair\", \"hour_of_day\", \"ret\")\n",
    "# )\n",
    "\n",
    "# # 2) Overall stats per pair: n, sum(ret), sum(ret^2)\n",
    "# overall_stats = (\n",
    "#     df_returns\n",
    "#     .groupBy(\"pair\")\n",
    "#     .agg(\n",
    "#         F.count(\"*\").alias(\"n\"),\n",
    "#         F.sum(\"ret\").alias(\"sum_y\"),\n",
    "#         F.sum(F.pow(F.col(\"ret\"), 2)).alias(\"sum_y2\")\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # 3) Per-hour stats per pair: n_h, sum(ret at that hour)\n",
    "# hour_stats = (\n",
    "#     df_returns\n",
    "#     .groupBy(\"pair\", \"hour_of_day\")\n",
    "#     .agg(\n",
    "#         F.count(\"*\").alias(\"n_h\"),\n",
    "#         F.sum(\"ret\").alias(\"sum_y_h\")\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # 4) Join and compute corr( 1[hour==h], ret ) analytically\n",
    "# stats = hour_stats.join(overall_stats, on=\"pair\", how=\"inner\")\n",
    "\n",
    "# stats = (\n",
    "#     stats\n",
    "#     # probabilities and expectations\n",
    "#     .withColumn(\"p\", F.col(\"n_h\") / F.col(\"n\"))\n",
    "#     .withColumn(\"Ey\", F.col(\"sum_y\") / F.col(\"n\"))\n",
    "#     .withColumn(\"Ey2\", F.col(\"sum_y2\") / F.col(\"n\"))\n",
    "#     .withColumn(\"Exy\", F.col(\"sum_y_h\") / F.col(\"n\"))\n",
    "#     # covariance and variances\n",
    "#     .withColumn(\"cov\", F.col(\"Exy\") - F.col(\"p\") * F.col(\"Ey\"))\n",
    "#     .withColumn(\"varx\", F.col(\"p\") - F.col(\"p\") * F.col(\"p\"))\n",
    "#     .withColumn(\"vary\", F.col(\"Ey2\") - F.col(\"Ey\") * F.col(\"Ey\"))\n",
    "#     # correlation\n",
    "#     .withColumn(\n",
    "#         \"corr\",\n",
    "#         F.when((F.col(\"varx\") <= 0) | (F.col(\"vary\") <= 0),\n",
    "#                F.lit(None).cast(\"double\"))\n",
    "#          .otherwise(F.col(\"cov\") / F.sqrt(F.col(\"varx\") * F.col(\"vary\")))\n",
    "#     )\n",
    "#     # clip to [-0.5, 0.5]\n",
    "#     .withColumn(\n",
    "#         \"corr_clipped\",\n",
    "#         F.when(F.col(\"corr\") > 0.5, 0.5)\n",
    "#          .when(F.col(\"corr\") < -0.5, -0.5)\n",
    "#          .otherwise(F.col(\"corr\"))\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # 5) Bring only the small correlation table to pandas\n",
    "# pdf_corr = (\n",
    "#     stats\n",
    "#     .select(\"pair\", \"hour_of_day\", \"corr_clipped\")\n",
    "#     .toPandas()\n",
    "# )\n",
    "\n",
    "# # Pivot into heatmap shape: rows = pair, cols = hour 023\n",
    "# heatmap_df = pdf_corr.pivot(\n",
    "#     index=\"pair\",\n",
    "#     columns=\"hour_of_day\",\n",
    "#     values=\"corr_clipped\"\n",
    "# )\n",
    "\n",
    "# # Ensure all 24 hours are present as columns (023)\n",
    "# all_hours = list(range(24))\n",
    "# for h in all_hours:\n",
    "#     if h not in heatmap_df.columns:\n",
    "#         heatmap_df[h] = np.nan\n",
    "\n",
    "# heatmap_df = heatmap_df[all_hours].sort_index()\n",
    "\n",
    "# # 6) Plot heatmap\n",
    "# colors = [\"red\", \"white\", \"green\"]\n",
    "# custom_cmap = LinearSegmentedColormap.from_list(\"rwg\", colors, N=256)\n",
    "\n",
    "# plt.figure(figsize=(18, 10))\n",
    "# sns.heatmap(\n",
    "#     heatmap_df,\n",
    "#     cmap=custom_cmap,\n",
    "#     vmin=-0.01, vmax=0.01,\n",
    "#     linewidths=0.4,\n",
    "#     cbar_kws={\"label\": \"Correlation( 1[hour==h], return )\"}\n",
    "# )\n",
    "\n",
    "# plt.title(\"Correlation Between Returns and Hour of Day\")\n",
    "# plt.xlabel(\"Hour of Day (023)\")\n",
    "# plt.ylabel(\"BaseQuote Pair\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
