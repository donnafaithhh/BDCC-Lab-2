{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b1154d9-f090-4b0c-9709-0bcb8f0423a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script src=\"require.js\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<script src=\"require.js\"></script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "166f8f17-6c4f-4e3d-b006-f6c97d9bb74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js \"></script><script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       "if (code_show){\n",
       "$('div.jp-CodeCell > div.jp-Cell-inputWrapper').hide();\n",
       "} else {\n",
       "$('div.jp-CodeCell > div.jp-Cell-inputWrapper').show();\n",
       "}\n",
       "code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);</script><form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js \"></script><script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    "if (code_show){\n",
    "$('div.jp-CodeCell > div.jp-Cell-inputWrapper').hide();\n",
    "} else {\n",
    "$('div.jp-CodeCell > div.jp-Cell-inputWrapper').show();\n",
    "}\n",
    "code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);</script><form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e9b536-8ccd-4527-95c7-c8c359fe5ac2",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"Figures/Title.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d7c269-e0b2-4661-8649-fda38188f9e1",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #270f47; color: #eed47c; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "# I. Table of Contents\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a341bdc-50d2-4fe5-80c1-a5aa1d111e3e",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #270f47; color: #eed47c; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "# II. Introduction\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23f32a1-8007-44ce-8dd0-afb81513f191",
   "metadata": {},
   "source": [
    "<div style=\"color: #270f47; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f780b18a-bf5a-4c0e-804f-d8d76eda1351",
   "metadata": {},
   "source": [
    "<div style=\"color: #270f47; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "## Motivation\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab387656-4acc-494c-8bbc-82a3e008dda0",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #270f47; color: #eed47c; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "# III. Methodology Overview\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9ca1c2-90bf-4f9c-b61d-5d2fcb45fe6d",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"Figures/Methodology Overview.png\" />\n",
    "</div>\n",
    "\n",
    "The figure above shows the methodology overview of this study.\n",
    "Our methodology consists of a four step process starting with the collection of historical Binance data, followed by exploratory data analysis, data processing, and the results and discussion. \n",
    "Under the results and discussion portion, we would also discuss the potential impacts this can have on investors, the perceived benefits and disadvantages, our recommendations and conclusions. \n",
    "\n",
    "Below would be a short summary of each of the different steps:\n",
    "1. **Data Collection**: Here, we collect publicly available historical Binance data focusing on the closing price. Since the dataset is very big, we stored it in a Spark DataFrame.\n",
    "2. **Exploratory Data Analysis**: Here, we prepared and cleaned the dataset to ensure that it is suitable for further analysis. EDA is used to understand the behavior of the closing price for different classifications: base currencies, quote currencies, and even their classifications. These would be further discussed later on.\n",
    "3. **Data Processing**: In this step, we want to get answers for our research problem which is to find out the volatility, price stability, and trading activity patterns among the three classifications: cryptocurrency, fiat-based tokens, and stablecoin.\n",
    "4. **Results and Discussion**: Based on what we find, we want to discuss what this could mean for investors, mention our perceived benefits and disadvantages, and recommend further steps. Afterwards, we will summarize findings in the recommendations and conclusion section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8785c701-4134-489a-9484-ce034836a094",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #270f47; color: #eed47c; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "# IV. Data Collection\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6abbe7-53dc-409e-a9df-fbc3212d4835",
   "metadata": {},
   "source": [
    "<div style=\"color: #270f47; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "## Data Source\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eec5a0a-ee6e-4ab2-923c-5a53a6f70173",
   "metadata": {},
   "source": [
    "We gathered data from the Binance Full History dataset available on the Jojie-collected public datasets of the Asian Institute of Management. \n",
    "The directory is as follows: `/mnt/data/public/binance-full-history`.\n",
    "This dataset consists of more than 30 Parquet files that correspond to the information per base currency in its quote currency.\n",
    "The dataset, as a whole, takes up 33 GB of data, so it would not be feasible to use the typical Python operations to handle all of it. \n",
    "Instead, we used Apache Spark, and created a Spark DataFrame just to contain all the information we need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04a6fd5-292e-44bb-98b0-cb9ad04aeb4b",
   "metadata": {},
   "source": [
    "<div style=\"color: #270f47; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "## Data Description\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d410b4f-5ed0-4f96-8b91-3d572d38e4d7",
   "metadata": {},
   "source": [
    "The following features are consistent within all Parquet files in the Binance Full History dataset:\n",
    "\n",
    "| Feature Name | Data Description | Data Type |\n",
    "|-------------|-----------------|-----------|\n",
    "| open | Opening price of the trading period | float |\n",
    "| high | Highest price during the trading period | float |\n",
    "| low | Lowest price during the trading period | float |\n",
    "| close | Closing price of the trading period | float |\n",
    "| volume | Total volume of base asset traded | float |\n",
    "| quote_asset_volume | Total volume of quote asset traded | float |\n",
    "| number_of_trades | Total number of trades executed | integer |\n",
    "| taker_buy_base_asset_volume | Volume of base asset bought by takers | float |\n",
    "| taker_buy_quote_asset_volume | Volume of quote asset bought by takers | float |\n",
    "| open_time | Timestamp when the trading period started | timestamp_ntz |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1ab3dc-3ac2-4a5d-a76b-ed6d72786398",
   "metadata": {},
   "source": [
    "<div style=\"color: #270f47; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "## Data Collection and DataFrame Creation\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1376c807-2dae-4b52-97f7-d63051bafc21",
   "metadata": {},
   "source": [
    "Since there are a lot of files, and the entire dataset sums to a total of 33 GB, we had to use Apache Spark to handle the data. \n",
    "To summarize the code below, we created a Spark DataFrame from all the information available.\n",
    "Here, we created new features: `base_currency`, `quote_currency`, and `classification`. \n",
    "These three are not anywhere in the previously shown data dictionary because they are information you can only get from the file names of the Parquet files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bad2016e-d536-4026-8eaf-eee1b3573808",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfunctools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m reduce\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# spark imports\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msql\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msql\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functions \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msql\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FloatType\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "# standard imports\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "\n",
    "# spark imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import FloatType\n",
    "import pyspark.sql.window as window\n",
    "from pyspark.sql.functions import col, split, when, lit\n",
    "from pyspark.sql.functions import regexp_extract, input_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cf81bd-f344-4778-b6e8-70991b25a73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the parquet files\n",
    "directory = '/mnt/data/public/binance-full-history'\n",
    "files = [f for f in os.listdir(directory) if f.endswith('.parquet')]\n",
    "\n",
    "base_quote_counts = {}\n",
    "\n",
    "for file in files:\n",
    "    # Get base and quote per file name\n",
    "    base_currency = file.split('-')[0]\n",
    "    quote_currency = file.split('-')[1].replace('.parquet', '')\n",
    "    \n",
    "    if base_currency not in base_quote_counts:\n",
    "        base_quote_counts[base_currency] = set()\n",
    "    \n",
    "    base_quote_counts[base_currency].add(quote_currency)\n",
    "\n",
    "# Convert to counts\n",
    "base_counts = {base: len(quotes) for base, quotes in base_quote_counts.items()}\n",
    "\n",
    "# Create dataframe for plotting\n",
    "counts_df = pd.DataFrame({\n",
    "    'base_currency': list(base_counts.keys()),\n",
    "    'quote_count': list(base_counts.values())\n",
    "})\n",
    "quote_count_distribution = counts_df['quote_count'].value_counts().sort_index()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 8))\n",
    "bars = plt.bar(\n",
    "    quote_count_distribution.index, quote_count_distribution.values\n",
    ")\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "             f'{int(height)}', ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('Number of Quote Currencies')\n",
    "plt.ylabel('Number of Base Currencies')\n",
    "plt.title('Distribution of Base Currencies by Number of Quote Currencies')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(quote_count_distribution.index)\n",
    "\n",
    "# Saving the figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    'Figures/Distribution of Base Currencies by Number of Quote Currencies.png'\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Get top base currencies\n",
    "top_bases = counts_df.nlargest(10, 'quote_count')\n",
    "common_quotes = set.intersection(*(base_quote_counts[base] for base in top_bases['base_currency']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cff0d6-f690-4cc9-82df-085b4c82a537",
   "metadata": {},
   "source": [
    "As seen here, there are a lot of files, but most of them only have one quote currency.\n",
    "Furthermore, there are also not a lot of base currencies that have a lot of the same quote currencies.\n",
    "Since we want to do a comparative analysis on the different quote currencies and their relationship to the base currency, we will only look at the top 10 base currencies so that we have files that we can compare with others.\n",
    "Additionally, we will also only look at the same quote currencices that are across all the top 10 base currencies.\n",
    "This cuts down on a lot of irrelevant data that are not important to our analysis and makes this more computationally efficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9427eb2-7db9-4b4f-9878-df592dfcf376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"TopBasesAnalysis\").getOrCreate()\n",
    "directory = '/mnt/data/public/binance-full-history'\n",
    "\n",
    "# Getting only target files\n",
    "file_data = []\n",
    "for base in top_bases['base_currency']:\n",
    "    for quote in common_quotes:\n",
    "        file_name = f\"{base}-{quote}.parquet\"\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        if os.path.exists(file_path):\n",
    "            file_data.append((file_path, base, quote))\n",
    "\n",
    "# Define classification mapping\n",
    "classification_map = {\n",
    "    'stablecoin': ['BUSD', 'USDT'],\n",
    "    'fiat': ['EUR']\n",
    "}\n",
    "\n",
    "# Create DataFrames for each file and add columns\n",
    "dfs = []\n",
    "for file_path, base, quote in file_data:\n",
    "    df = spark.read.parquet(file_path)\n",
    "    df = df.withColumn(\"base_currency\", lit(base)) \\\n",
    "           .withColumn(\"quote_currency\", lit(quote)) \\\n",
    "           .withColumn(\"classification\", \n",
    "                      when(lit(quote).isin(classification_map['stablecoin']), lit('stablecoin'))\n",
    "                      .when(lit(quote).isin(classification_map['fiat']), lit('fiat'))\n",
    "                      .otherwise(lit('cryptocurrency')))\n",
    "    dfs.append(df)\n",
    "\n",
    "# Union all DataFrames\n",
    "spark_df = reduce(lambda df1, df2: df1.union(df2), dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ec9e34-a90e-476e-af69-a98d00b52ac4",
   "metadata": {},
   "source": [
    "The schema, also features, of the new Spark DataFrame is as follows:\n",
    "\n",
    "| Feature | Description | Data Type |\n",
    "|---------|-------------|-----------|\n",
    "| open | Opening price of the trading period | float |\n",
    "| high | Highest price during the trading period | float |\n",
    "| low | Lowest price during the trading period | float |\n",
    "| close | Closing price of the trading period | float |\n",
    "| volume | Total trading volume in base currency | float |\n",
    "| quote_asset_volume | Total trading volume in quote currency | float |\n",
    "| number_of_trades | Total number of trades executed during the period | integer |\n",
    "| taker_buy_base_asset_volume | Volume of base asset bought by takers (market orders) | float |\n",
    "| taker_buy_quote_asset_volume | Volume of quote asset bought by takers (market orders) | float |\n",
    "| open_time | Timestamp indicating the start of the trading period | timestamp_ntz |\n",
    "| base_currency | The base currency in the trading pair (e.g., BTC, ETH) | string |\n",
    "| quote_currency | The quote currency in the trading pair (e.g., USDT, BUSD) | string |\n",
    "| classification | Classification of the quote currency (stablecoin/fiat/cryptocurrency) | string |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d0e7d0-206c-4e83-bfc7-8e09520c386d",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #270f47; color: #eed47c; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "# V. Exploratory Data Analysis\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891f3420-564d-44f5-a6b8-fe190aa9938d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a48b8ae-84a0-4d54-bf32-23492389471a",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #270f47; color: #eed47c; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "# VI. Data Processing\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c99bff-d4f9-4675-821e-2b8a4be3d37f",
   "metadata": {},
   "source": [
    "In this portion, we are trying to fulfill our goals where we compare volatility, price stability, and trading activity patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49af6c18-6470-4a5d-b575-ea7a3dc4e488",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #270f47; color: #eed47c; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "# VII. Results and Discussion\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf7c135-de61-4cab-89dc-af6dbbf3b710",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #270f47; color: #eed47c; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "# VIII. Conclusion and Recommendations\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59dfa14-02ab-4501-9541-cbb1b4f84101",
   "metadata": {},
   "source": [
    "<div style=\"color: #270f47; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6f0158-fc98-4260-9e4c-c50896b586d3",
   "metadata": {},
   "source": [
    "<div style=\"color: #270f47; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "## Recommendations\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e688b57-9077-47ae-b66c-7736bb38d8ff",
   "metadata": {},
   "source": [
    "### Limitations of the Study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398ea987-2d5a-449a-91e6-f37de38f6a2e",
   "metadata": {},
   "source": [
    "insert your text here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd414bcd-571f-4a45-a10d-5a76d585bcce",
   "metadata": {},
   "source": [
    "### Recommendations for Readers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d18865-d4af-4863-a40b-4492d67448a8",
   "metadata": {},
   "source": [
    "insert your text here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23b9d3f-047b-4ebe-880f-04d21fa82b4a",
   "metadata": {},
   "source": [
    "### Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6751e6c5-3821-4218-8bfa-abb9cfeb5f85",
   "metadata": {},
   "source": [
    "insert your text here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9bf639-35c1-4499-96ae-b41335a6d2d7",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #270f47; color: #eed47c; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "# IX. References\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8853cb8b-da18-4a01-bcf1-11a5851a26ae",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #270f47; color: #eed47c; padding: 15px; text-align: left; border-radius: 5px;\">\n",
    "\n",
    "# X. Supplementary\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621c684f-600e-4e02-9b2d-6c1fc06d40ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
