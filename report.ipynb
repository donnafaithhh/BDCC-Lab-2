{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d247e237-fb8f-48f9-8b71-803f2134ec23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T06:33:12.338737Z",
     "iopub.status.busy": "2025-11-19T06:33:12.337991Z",
     "iopub.status.idle": "2025-11-19T06:33:12.348729Z",
     "shell.execute_reply": "2025-11-19T06:33:12.347086Z",
     "shell.execute_reply.started": "2025-11-19T06:33:12.338648Z"
    }
   },
   "outputs": [],
   "source": [
    "# typical\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, desc\n",
    "from pyspark.sql.functions import col, lag\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb588d2e-b146-4157-b30c-8d919138b479",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T06:33:12.807427Z",
     "iopub.status.busy": "2025-11-19T06:33:12.806743Z",
     "iopub.status.idle": "2025-11-19T06:33:13.137792Z",
     "shell.execute_reply": "2025-11-19T06:33:13.136000Z",
     "shell.execute_reply.started": "2025-11-19T06:33:12.807368Z"
    }
   },
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "     .builder\n",
    "     .master('local[*]')\n",
    "     .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32857b1-a2a8-4a52-9c26-f796b40a3310",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:55:22.148313Z",
     "iopub.status.busy": "2025-11-17T14:55:22.147056Z",
     "iopub.status.idle": "2025-11-17T14:55:22.160570Z",
     "shell.execute_reply": "2025-11-17T14:55:22.158200Z",
     "shell.execute_reply.started": "2025-11-17T14:55:22.148242Z"
    }
   },
   "source": [
    "Note: Check the `lab2.py` file for proof of concept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7443628-5acc-48b7-99d9-244b51eafd40",
   "metadata": {},
   "source": [
    "# Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47fcfe7-d1e6-43d9-ab64-ccdc78bdd60e",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8905eae9-e684-4883-b295-0bbd430fe3d4",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa96844-3132-4c4e-b805-536f10efaa7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:50:55.056109Z",
     "iopub.status.busy": "2025-11-17T14:50:55.055403Z",
     "iopub.status.idle": "2025-11-17T14:50:55.063436Z",
     "shell.execute_reply": "2025-11-17T14:50:55.062016Z",
     "shell.execute_reply.started": "2025-11-17T14:50:55.056045Z"
    }
   },
   "source": [
    "**Loading the File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "770244d7-7c2e-427d-8861-08d0736082ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T06:33:14.766815Z",
     "iopub.status.busy": "2025-11-19T06:33:14.766033Z",
     "iopub.status.idle": "2025-11-19T06:33:20.748353Z",
     "shell.execute_reply": "2025-11-19T06:33:20.746945Z",
     "shell.execute_reply.started": "2025-11-19T06:33:14.766754Z"
    }
   },
   "outputs": [],
   "source": [
    "directory = '/mnt/data/public/binance-full-history'\n",
    "binance = spark.read.parquet(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5261ecb-11ff-42d0-882a-f0799b137e39",
   "metadata": {},
   "source": [
    "Just to have a look at all the column names and see what columns are to be referenced when all the parquet files will be combined into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88e8c305-bfda-4447-a32b-ac761f92c592",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T06:33:22.778142Z",
     "iopub.status.busy": "2025-11-19T06:33:22.777364Z",
     "iopub.status.idle": "2025-11-19T06:33:22.816586Z",
     "shell.execute_reply": "2025-11-19T06:33:22.815247Z",
     "shell.execute_reply.started": "2025-11-19T06:33:22.778056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- open: float (nullable = true)\n",
      " |-- high: float (nullable = true)\n",
      " |-- low: float (nullable = true)\n",
      " |-- close: float (nullable = true)\n",
      " |-- volume: float (nullable = true)\n",
      " |-- quote_asset_volume: float (nullable = true)\n",
      " |-- number_of_trades: integer (nullable = true)\n",
      " |-- taker_buy_base_asset_volume: float (nullable = true)\n",
      " |-- taker_buy_quote_asset_volume: float (nullable = true)\n",
      " |-- open_time: timestamp_ntz (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "binance.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76aa9b9d-33d4-4893-a136-ec098464d054",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T06:33:23.478298Z",
     "iopub.status.busy": "2025-11-19T06:33:23.477601Z",
     "iopub.status.idle": "2025-11-19T06:33:23.487490Z",
     "shell.execute_reply": "2025-11-19T06:33:23.485590Z",
     "shell.execute_reply.started": "2025-11-19T06:33:23.478240Z"
    }
   },
   "outputs": [],
   "source": [
    "files = os.listdir(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa8c862-ba27-496b-a868-ed9d795c41d8",
   "metadata": {},
   "source": [
    "**Filtering the Files According to Coin Classification**\n",
    "\n",
    "First, all the files were classified according to either three coin types: cyrptocurrency, stablecoin, and fiat-backed. Something to note is that filenames such as `BTC-USDT.parquet` were classified under the *base asset*, which refers to the first coin in the title (BTC), and the second coin (USDT) means that it's being expressed in terms of that pricing. So, the given example would be classified as a cryptocurrency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f484590-9fe3-45cf-a221-9c6cb2b543da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T06:33:24.062452Z",
     "iopub.status.busy": "2025-11-19T06:33:24.061769Z",
     "iopub.status.idle": "2025-11-19T06:33:24.087235Z",
     "shell.execute_reply": "2025-11-19T06:33:24.086320Z",
     "shell.execute_reply.started": "2025-11-19T06:33:24.062395Z"
    }
   },
   "outputs": [],
   "source": [
    "# Base Classifications (cryptocurrencies, stablecoins, and fiats)\n",
    "cryptos = [\n",
    "    '1INCH', 'AAVE', 'ACM', 'ADA', 'ADADOWN', 'ADAUP', 'ADX', 'AE', 'AERGO', 'AGI',\n",
    "    'AION', 'AKRO', 'ALGO', 'ALICE', 'ALPHA', 'AMB', 'ANKR', 'ANT', 'APPC', 'AR',\n",
    "    'ARDR', 'ARK', 'ARN', 'ARPA', 'ASR', 'AST', 'ATA', 'ATM', 'ATOM', 'AUCTION',\n",
    "    'AUDIO', 'BCH', 'BEAM', 'BEL', 'BETA', 'BETH', 'BIFI', 'BLZ', 'BNB', 'BNBDOWN',\n",
    "    'BNBUP', 'BNT', 'BQX', 'BRD', 'BTC', 'BTCDOWN', 'BTCST', 'BTCUP', 'BTG', 'BTS',\n",
    "    'BTT', 'BURGER', 'BZRX', 'C98', 'CAKE', 'CTK', 'CTSI', 'CTXC', 'CVC', 'CVP',\n",
    "    'DAR', 'DASH', 'DATA', 'DCR', 'DEGO', 'DENT', 'DEXE', 'DF', 'DGB', 'DGD', 'DIA',\n",
    "    'DLT', 'DNT', 'DOCK', 'DODO', 'DOGE', 'DOT', 'DOTDOWN', 'DOTUP', 'DREP', 'DUSK',\n",
    "    'DYDX', 'EDO', 'EGLD', 'ELF', 'ENG', 'ENJ', 'EOS', 'ETC', 'ETH', 'FET', 'FIL',\n",
    "    'FIO', 'FIRO', 'FIS', 'FLM', 'FLOW', 'FOR', 'FORTH', 'FRONT', 'FTM', 'FTT',\n",
    "    'FUEL', 'FUN', 'FXS', 'GALA', 'GAS', 'GHST', 'GLM', 'GNT', 'GO', 'GRS', 'GRT',\n",
    "    'GTC', 'GTO', 'GVT', 'GXS', 'HARD', 'HBAR', 'HC', 'HIVE', 'HNT', 'HOT', 'ICP',\n",
    "    'ICX', 'IOTA', 'KSM', 'LAZIO', 'LEND', 'LINA', 'LINK', 'LINKDOWN', 'LINKUP',\n",
    "    'LIT', 'LOOM', 'LPT', 'LRC', 'LSK', 'LTC', 'LTCDOWN', 'LTCUP', 'LTO', 'LUN',\n",
    "    'LUNA', 'MANA', 'MASK', 'MATIC', 'MBL', 'MBOX', 'MCO', 'MDA', 'MDT', 'MDX',\n",
    "    'MFT', 'MINA', 'MIR', 'MITH', 'NEO', 'OCEAN', 'OG', 'OGN', 'OM', 'OMG', 'ONE',\n",
    "    'ONG', 'ONT', 'ORN', 'OST', 'OXT', 'PAXG', 'PERL', 'PERP', 'PHA', 'PHB', 'PIVX',\n",
    "    'PNT', 'POA', 'POE', 'POLS', 'POLY', 'POND', 'POWR', 'PPT', 'PROM', 'PROS',\n",
    "    'PSG', 'PUNDIX', 'QKC', 'QLC', 'QNT', 'QSP', 'QTUM', 'RAMP', 'RCN', 'RDN',\n",
    "    'REEF', 'REN', 'REP', 'REQ', 'SNGLS', 'SNM', 'SNT', 'SNX', 'SOL', 'SPARTA',\n",
    "    'SRM', 'STEEM', 'STMX', 'STORJ', 'STORM', 'STPT', 'STRAT', 'STRAX', 'STX',\n",
    "    'SUN', 'SUPER', 'SUSHI', 'SUSHIDOWN', 'SUSHIUP', 'SXP', 'SXPUP', 'SYS', 'TCT',\n",
    "    'TFUEL', 'THETA', 'TKO', 'TLM', 'TNB', 'TNT', 'TOMO', 'TORN', 'TRB', 'TROY',\n",
    "    'TRX', 'VET', 'VIA', 'VIB', 'VIBE', 'VIDT', 'VITE', 'VTHO', 'WABI', 'WAN',\n",
    "    'WAVES', 'WBTC', 'WIN', 'WING', 'WNXM', 'WPR', 'WRX', 'WTC', 'XEC', 'XEM',\n",
    "    'XLM', 'XMR', 'XRP', 'XRPDOWN', 'XRPUP', 'XTZ']\n",
    "stablecoins = ['USDT','USDC','BUSD','TUSD','DAI','PAX','BIDR','IDRT']\n",
    "fiats = ['EUR','GBP','AUD','TRY','BRL','RUB','NGN','UAH']\n",
    "\n",
    "classified = {\n",
    "    \"cryptocurrency\": [],\n",
    "    \"stablecoin\": [],\n",
    "    \"fiat_backed\": []\n",
    "}\n",
    "\n",
    "for f in files:\n",
    "    pair = f.replace('.parquet','')\n",
    "    base, quote = pair.split('-')\n",
    "    \n",
    "    if base in cryptos:\n",
    "        classified[\"cryptocurrency\"].append(f)\n",
    "    elif base in stablecoins:\n",
    "        classified[\"stablecoin\"].append(f)\n",
    "    elif base in fiats:\n",
    "        classified[\"fiat_backed\"].append(f)\n",
    "    else:\n",
    "        # unlisted base asset\n",
    "        classified[\"cryptocurrency\"].append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb8dc21a-a687-466b-9707-50a2172662f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T06:33:24.631044Z",
     "iopub.status.busy": "2025-11-19T06:33:24.630358Z",
     "iopub.status.idle": "2025-11-19T06:33:24.640967Z",
     "shell.execute_reply": "2025-11-19T06:33:24.638994Z",
     "shell.execute_reply.started": "2025-11-19T06:33:24.630988Z"
    }
   },
   "outputs": [],
   "source": [
    "classification = {}\n",
    "\n",
    "for category, file_list in classified.items():\n",
    "    for f in file_list:\n",
    "        pair = f.replace(\".parquet\", \"\")\n",
    "        classification[pair] = category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43d1297-ded6-49e3-9728-5d902e899ffe",
   "metadata": {},
   "source": [
    "After getting the coin classifications of the files, all the parquet files were combined into a single dataframe and was saved into a CSV & parquet copy after execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d686e5-f23a-47b7-893f-c024a0fc200f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T06:33:25.526902Z",
     "iopub.status.busy": "2025-11-19T06:33:25.526114Z"
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# set shuffle partitions BEFORE the transformations / writes\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"200\")  # or 300, 400, etc.\n",
    "\n",
    "# Add stock column from filename\n",
    "binance_with_stock = binance.withColumn(\n",
    "    \"stock\",\n",
    "    F.regexp_extract(F.input_file_name(), r'([^/]+)\\.parquet$', 1)\n",
    ")\n",
    "\n",
    "# Build proper classification DataFrame\n",
    "class_rows = [\n",
    "    (pair, category)\n",
    "    for pair, category in classification.items()\n",
    "]\n",
    "\n",
    "class_df = spark.createDataFrame(class_rows, [\"stock\", \"classification\"])\n",
    "\n",
    "# Window per token\n",
    "w = Window.partitionBy(\"stock\").orderBy(\"open_time\")\n",
    "\n",
    "final_spark_df = (\n",
    "    binance_with_stock\n",
    "    .join(class_df, on=\"stock\", how=\"left\")\n",
    "\n",
    "    # split stock into base + quote\n",
    "    .withColumn(\"base_currency\", F.split(F.col(\"stock\"), \"-\")[0])\n",
    "    .withColumn(\"quote_currency\", F.split(F.col(\"stock\"), \"-\")[1])\n",
    "\n",
    "    .withColumn(\"prev_close\", F.lag(\"close\").over(w))\n",
    "\n",
    "    # returns\n",
    "    .withColumn(\"return\", (F.col(\"close\") - F.col(\"prev_close\")) / F.col(\"prev_close\"))\n",
    "    .withColumn(\"abs_return\", F.abs(F.col(\"return\")))\n",
    "\n",
    "    # log returns\n",
    "    .withColumn(\"log_return\", F.log(F.col(\"close\") / F.col(\"prev_close\")))\n",
    "    .withColumn(\"abs_log_return\", F.abs(F.col(\"log_return\")))\n",
    "\n",
    "    .dropna(subset=[\"return\", \"log_return\"])\n",
    "\n",
    "    .select(\n",
    "        \"base_currency\",\n",
    "        \"quote_currency\",\n",
    "        \"classification\",\n",
    "        \"open\",\n",
    "        \"high\",\n",
    "        \"low\",\n",
    "        \"close\",\n",
    "        \"volume\",\n",
    "        \"quote_asset_volume\",\n",
    "        \"number_of_trades\",\n",
    "        \"taker_buy_base_asset_volume\",\n",
    "        \"taker_buy_quote_asset_volume\",\n",
    "        \"open_time\",\n",
    "        \"return\",\n",
    "        \"abs_return\",\n",
    "        \"log_return\",\n",
    "        \"abs_log_return\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# sanity check\n",
    "final_spark_df.show(5)\n",
    "\n",
    "# add the year column once\n",
    "final_with_year = final_spark_df.withColumn(\"year\", F.year(\"open_time\"))\n",
    "\n",
    "# see what years you have\n",
    "(\n",
    "    final_with_year\n",
    "    .select(\"year\")\n",
    "    .distinct()\n",
    "    .orderBy(\"year\")\n",
    "    .show()\n",
    ")\n",
    "\n",
    "# single write, partitioned by year\n",
    "(\n",
    "    final_with_year\n",
    "    .repartition(\"year\")          # helps spread data by year\n",
    "    .write\n",
    "    .mode(\"overwrite\")            # overwrite the whole dataset\n",
    "    .partitionBy(\"year\")          # creates year=2017, year=2018, ...\n",
    "    .parquet(\"final_output_by_year\")\n",
    ")\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184574fb-d2e3-47a7-b43a-ae6991cbc9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
