{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d247e237-fb8f-48f9-8b71-803f2134ec23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T05:49:34.014483Z",
     "iopub.status.busy": "2025-11-18T05:49:34.014272Z",
     "iopub.status.idle": "2025-11-18T05:49:35.578866Z",
     "shell.execute_reply": "2025-11-18T05:49:35.577770Z",
     "shell.execute_reply.started": "2025-11-18T05:49:34.014462Z"
    }
   },
   "outputs": [],
   "source": [
    "# typical\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, desc\n",
    "from pyspark.sql.functions import col, lag\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb588d2e-b146-4157-b30c-8d919138b479",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T05:49:36.050463Z",
     "iopub.status.busy": "2025-11-18T05:49:36.049084Z",
     "iopub.status.idle": "2025-11-18T05:49:41.806032Z",
     "shell.execute_reply": "2025-11-18T05:49:41.803595Z",
     "shell.execute_reply.started": "2025-11-18T05:49:36.050394Z"
    }
   },
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "     .builder\n",
    "     .master('local[*]')\n",
    "     .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32857b1-a2a8-4a52-9c26-f796b40a3310",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:55:22.148313Z",
     "iopub.status.busy": "2025-11-17T14:55:22.147056Z",
     "iopub.status.idle": "2025-11-17T14:55:22.160570Z",
     "shell.execute_reply": "2025-11-17T14:55:22.158200Z",
     "shell.execute_reply.started": "2025-11-17T14:55:22.148242Z"
    }
   },
   "source": [
    "Note: Check the `lab2.py` file for proof of concept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7443628-5acc-48b7-99d9-244b51eafd40",
   "metadata": {},
   "source": [
    "# Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47fcfe7-d1e6-43d9-ab64-ccdc78bdd60e",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8905eae9-e684-4883-b295-0bbd430fe3d4",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa96844-3132-4c4e-b805-536f10efaa7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:50:55.056109Z",
     "iopub.status.busy": "2025-11-17T14:50:55.055403Z",
     "iopub.status.idle": "2025-11-17T14:50:55.063436Z",
     "shell.execute_reply": "2025-11-17T14:50:55.062016Z",
     "shell.execute_reply.started": "2025-11-17T14:50:55.056045Z"
    }
   },
   "source": [
    "**Loading the File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "770244d7-7c2e-427d-8861-08d0736082ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T05:49:44.379330Z",
     "iopub.status.busy": "2025-11-18T05:49:44.378240Z",
     "iopub.status.idle": "2025-11-18T05:49:51.087502Z",
     "shell.execute_reply": "2025-11-18T05:49:51.086474Z",
     "shell.execute_reply.started": "2025-11-18T05:49:44.379253Z"
    }
   },
   "outputs": [],
   "source": [
    "directory = '/mnt/data/public/binance-full-history'\n",
    "binance = spark.read.parquet(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5261ecb-11ff-42d0-882a-f0799b137e39",
   "metadata": {},
   "source": [
    "Just to have a look at all the column names and see what columns are to be referenced when all the parquet files will be combined into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88e8c305-bfda-4447-a32b-ac761f92c592",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T05:49:52.555170Z",
     "iopub.status.busy": "2025-11-18T05:49:52.553709Z",
     "iopub.status.idle": "2025-11-18T05:49:52.592771Z",
     "shell.execute_reply": "2025-11-18T05:49:52.590659Z",
     "shell.execute_reply.started": "2025-11-18T05:49:52.555107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- open: float (nullable = true)\n",
      " |-- high: float (nullable = true)\n",
      " |-- low: float (nullable = true)\n",
      " |-- close: float (nullable = true)\n",
      " |-- volume: float (nullable = true)\n",
      " |-- quote_asset_volume: float (nullable = true)\n",
      " |-- number_of_trades: integer (nullable = true)\n",
      " |-- taker_buy_base_asset_volume: float (nullable = true)\n",
      " |-- taker_buy_quote_asset_volume: float (nullable = true)\n",
      " |-- open_time: timestamp_ntz (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "binance.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76aa9b9d-33d4-4893-a136-ec098464d054",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T05:49:53.392086Z",
     "iopub.status.busy": "2025-11-18T05:49:53.390582Z",
     "iopub.status.idle": "2025-11-18T05:49:53.399856Z",
     "shell.execute_reply": "2025-11-18T05:49:53.398296Z",
     "shell.execute_reply.started": "2025-11-18T05:49:53.392023Z"
    }
   },
   "outputs": [],
   "source": [
    "files = os.listdir(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa8c862-ba27-496b-a868-ed9d795c41d8",
   "metadata": {},
   "source": [
    "**Filtering the Files According to Coin Classification**\n",
    "\n",
    "First, all the files were classified according to either three coin types: cyrptocurrency, stablecoin, and fiat-backed. Something to note is that filenames such as `BTC-USDT.parquet` were classified under the *base asset*, which refers to the first coin in the title (BTC), and the second coin (USDT) means that it's being expressed in terms of that pricing. So, the given example would be classified as a cryptocurrency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "445e7d4e-d586-4037-ad9b-17e3d8bc859a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T05:49:54.680560Z",
     "iopub.status.busy": "2025-11-18T05:49:54.679044Z",
     "iopub.status.idle": "2025-11-18T05:49:54.697411Z",
     "shell.execute_reply": "2025-11-18T05:49:54.695904Z",
     "shell.execute_reply.started": "2025-11-18T05:49:54.680496Z"
    }
   },
   "outputs": [],
   "source": [
    "# Base Classifications\n",
    "cryptos = [\n",
    "    'BTC','ETH','BNB','XRP','ADA','DOGE','SOL','MATIC','TRX','DOT','LTC','EOS','BCH','LINK','XLM','ATOM','ALGO','VET','FIL','NEO','IOTA','XTZ','ETC'\n",
    "]\n",
    "stablecoins = ['USDT','USDC','BUSD','TUSD','DAI','PAX','BIDR','IDRT']\n",
    "fiats = ['EUR','GBP','AUD','TRY','BRL','RUB','NGN','UAH']\n",
    "\n",
    "classified = {\n",
    "    \"cryptocurrency\": [],\n",
    "    \"stablecoin\": [],\n",
    "    \"fiat_backed\": []\n",
    "}\n",
    "\n",
    "for f in files:\n",
    "    pair = f.replace('.parquet','')\n",
    "    base, quote = pair.split('-')\n",
    "    \n",
    "    if base in cryptos:\n",
    "        classified[\"cryptocurrency\"].append(f)\n",
    "    elif base in stablecoins:\n",
    "        classified[\"stablecoin\"].append(f)\n",
    "    elif base in fiats:\n",
    "        classified[\"fiat_backed\"].append(f)\n",
    "    else:\n",
    "        # unlisted base asset\n",
    "        classified[\"cryptocurrency\"].append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb8dc21a-a687-466b-9707-50a2172662f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T05:49:56.882410Z",
     "iopub.status.busy": "2025-11-18T05:49:56.881012Z",
     "iopub.status.idle": "2025-11-18T05:49:56.891593Z",
     "shell.execute_reply": "2025-11-18T05:49:56.889850Z",
     "shell.execute_reply.started": "2025-11-18T05:49:56.882348Z"
    }
   },
   "outputs": [],
   "source": [
    "classification = {}\n",
    "\n",
    "for category, file_list in classified.items():\n",
    "    for f in file_list:\n",
    "        pair = f.replace(\".parquet\", \"\")\n",
    "        classification[pair] = category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43d1297-ded6-49e3-9728-5d902e899ffe",
   "metadata": {},
   "source": [
    "After getting the coin classifications of the files, all the parquet files were combined into a single dataframe and was saved into a CSV & parquet copy after execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d686e5-f23a-47b7-893f-c024a0fc200f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T06:05:39.378332Z",
     "iopub.status.busy": "2025-11-18T06:05:39.377616Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1) Add stock column from filename\n",
    "binance_with_stock = binance.withColumn(\n",
    "    \"stock\",\n",
    "    F.regexp_extract(F.input_file_name(), r'([^/]+)\\.parquet$', 1)\n",
    ")\n",
    "\n",
    "# 2) Build proper classification DataFrame\n",
    "class_rows = [\n",
    "    (stock.replace(\".parquet\", \"\"), class_name)\n",
    "    for class_name, stock_list in classification.items()\n",
    "    for stock in stock_list\n",
    "]\n",
    "class_df = spark.createDataFrame(class_rows, [\"stock\", \"classification\"])\n",
    "\n",
    "# 3) Window per token\n",
    "w = Window.partitionBy(\"stock\").orderBy(\"open_time\")\n",
    "\n",
    "final_spark_df = (\n",
    "    binance_with_stock\n",
    "    .join(class_df, on=\"stock\", how=\"left\")\n",
    "\n",
    "    # split stock into base + quote\n",
    "    .withColumn(\"base_currency\", F.split(F.col(\"stock\"), \"-\")[0])\n",
    "    .withColumn(\"quote_currency\", F.split(F.col(\"stock\"), \"-\")[1])\n",
    "\n",
    "    .withColumn(\"prev_close\", F.lag(\"close\").over(w))\n",
    "\n",
    "    # returns\n",
    "    .withColumn(\"return\", (F.col(\"close\") - F.col(\"prev_close\")) / F.col(\"prev_close\"))\n",
    "    .withColumn(\"abs_return\", F.abs(F.col(\"return\")))\n",
    "\n",
    "    # log returns\n",
    "    .withColumn(\"log_return\", F.log(F.col(\"close\") / F.col(\"prev_close\")))\n",
    "    .withColumn(\"abs_log_return\", F.abs(F.col(\"log_return\")))\n",
    "\n",
    "    .dropna(subset=[\"return\", \"log_return\"])\n",
    "\n",
    "    # drop prev_close if you don't need it anymore\n",
    "    # .drop(\"prev_close\")\n",
    "\n",
    "    .select(\n",
    "        \"base_currency\",\n",
    "        \"quote_currency\",\n",
    "        \"classification\",\n",
    "        \"open\",\n",
    "        \"high\",\n",
    "        \"low\",\n",
    "        \"close\",\n",
    "        \"volume\",\n",
    "        \"quote_asset_volume\",\n",
    "        \"number_of_trades\",\n",
    "        \"taker_buy_base_asset_volume\",\n",
    "        \"taker_buy_quote_asset_volume\",\n",
    "        \"open_time\",\n",
    "        \"return\",\n",
    "        \"abs_return\",\n",
    "        \"log_return\",\n",
    "        \"abs_log_return\"\n",
    "    )\n",
    ")\n",
    "\n",
    "final_spark_df.show(5)\n",
    "\n",
    "final_spark_df.write.mode(\"overwrite\").parquet(\"/mnt/data/final_output.parquet\")\n",
    "final_spark_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", True)\\\n",
    "    .csv(\"/mnt/data/final_output_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613b60aa-e1cc-493e-b420-29fda1a7ad8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
